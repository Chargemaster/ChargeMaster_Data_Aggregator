{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjyJBhgVt7CM"
   },
   "source": [
    "# Chargemaster Scraper\n",
    "This notebook will go over running the various code snippets which allow the web scraper to scrape chargemaster (CDM) files from WSHA associated hospitals.\n",
    "\n",
    "This was originally a Google colaboratory notebook and designed to run utilizing a Google Drive as mounted storage.\n",
    "\n",
    "This has since been modified to be able to be run locally. Some examples may not be optimized as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRDESM1YuFwU"
   },
   "source": [
    "## Install Relevant Packages\n",
    "Suggest utilizing a virtual environment. This code snippet assumes the working directory is the same as the one the notebook is located in. \n",
    "\n",
    "The \"requirements.txt\" is located one level above the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NYctZ3PHuf2m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: async-generator==1.10 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 1)) (1.10)\n",
      "Requirement already satisfied: attrs==21.2.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 2)) (21.2.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.10.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: brotlipy==0.7.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 4)) (0.7.0)\n",
      "Collecting bs4==0.0.1\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: certifi==2021.10.8 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 6)) (2021.10.8)\n",
      "Collecting cffi==1.15.0\n",
      "  Using cached cffi-1.15.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n",
      "Collecting charset-normalizer==2.0.8\n",
      "  Using cached charset_normalizer-2.0.8-py3-none-any.whl (39 kB)\n",
      "Collecting cryptography==36.0.0\n",
      "  Using cached cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "Collecting h11==0.12.0\n",
      "  Using cached h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Collecting idna==3.3\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting outcome==1.1.0\n",
      "  Using cached outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: pyOpenSSL==21.0.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 14)) (21.0.0)\n",
      "Requirement already satisfied: requests==2.26.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 15)) (2.26.0)\n",
      "Collecting selenium==4.1.0\n",
      "  Using cached selenium-4.1.0-py3-none-any.whl (958 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 17)) (1.16.0)\n",
      "Collecting sniffio==1.2.0\n",
      "  Using cached sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting sortedcontainers==2.4.0\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting soupsieve==2.3.1\n",
      "  Using cached soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Collecting trio==0.19.0\n",
      "  Using cached trio-0.19.0-py3-none-any.whl (356 kB)\n",
      "Collecting trio-websocket==0.9.2\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3==1.26.7 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 23)) (1.26.7)\n",
      "Collecting wsproto==1.0.0\n",
      "  Using cached wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting numpy==1.20.2\n",
      "  Downloading numpy-1.20.2-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.4 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==1.2.1\n",
      "  Downloading pandas-1.2.1-cp38-cp38-manylinux1_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==5.3.1\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dash==2.0.0\n",
      "  Downloading dash-2.0.0-py3-none-any.whl (7.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/jihk/anaconda3/lib/python3.8/site-packages (from pandas==1.2.1->-r ../requirements.txt (line 26)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jihk/anaconda3/lib/python3.8/site-packages (from pandas==1.2.1->-r ../requirements.txt (line 26)) (2021.3)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting Flask>=1.0.4\n",
      "  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dash-table==5.0.0\n",
      "  Downloading dash_table-5.0.0.tar.gz (3.4 kB)\n",
      "Collecting dash-html-components==2.0.0\n",
      "  Downloading dash_html_components-2.0.0.tar.gz (3.8 kB)\n",
      "Collecting flask-compress\n",
      "  Downloading Flask_Compress-1.10.1-py3-none-any.whl (7.9 kB)\n",
      "Collecting dash-core-components==2.0.0\n",
      "  Downloading dash_core_components-2.0.0.tar.gz (3.4 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from gunicorn==20.1.0->-r ../requirements.txt (line 29)) (58.0.4)\n",
      "Collecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /home/jihk/anaconda3/lib/python3.8/site-packages (from Flask>=1.0.4->dash==2.0.0->-r ../requirements.txt (line 28)) (8.0.3)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from Jinja2>=3.0->Flask>=1.0.4->dash==2.0.0->-r ../requirements.txt (line 28)) (2.0.1)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[K     |████████████████████████████████| 357 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: dash-core-components, dash-html-components, dash-table\n",
      "  Building wheel for dash-core-components (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dash-core-components: filename=dash_core_components-2.0.0-py3-none-any.whl size=3821 sha256=94ca6bd0a790d4fa5157efa1de7d4998c2940f1129bd22d218701d5139f04b28\n",
      "  Stored in directory: /home/jihk/.cache/pip/wheels/52/e4/f3/16724791571a955a46d54650510c98c04ab7d339626aee27cc\n",
      "  Building wheel for dash-html-components (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dash-html-components: filename=dash_html_components-2.0.0-py3-none-any.whl size=4089 sha256=83bae66feb9a79b1962ca0fa142810f3fe4d8dc53f773fc7a7aeca15dfdc7f91\n",
      "  Stored in directory: /home/jihk/.cache/pip/wheels/73/d8/8d/92f612c03c895f19bcc56a6c54be7bb41aaa698012a5624f60\n",
      "  Building wheel for dash-table (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dash-table: filename=dash_table-5.0.0-py3-none-any.whl size=3911 sha256=e38bfbbc50662150653bc933ee12893ee26556244317963acf809948e4d4b3f6\n",
      "  Stored in directory: /home/jihk/.cache/pip/wheels/a6/fb/f5/4adf241f384634f52028f15eab6a325e77b8766a0a00816bbf\n",
      "Successfully built dash-core-components dash-html-components dash-table\n",
      "Installing collected packages: pycparser, cffi, Werkzeug, sortedcontainers, sniffio, outcome, Jinja2, itsdangerous, idna, h11, cryptography, wsproto, trio, tenacity, soupsieve, Flask, brotli, trio-websocket, plotly, numpy, flask-compress, dash-table, dash-html-components, dash-core-components, charset-normalizer, selenium, pandas, gunicorn, dash, bs4\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.6\n",
      "    Uninstalling cffi-1.14.6:\n",
      "      Successfully uninstalled cffi-1.14.6\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.2\n",
      "    Uninstalling idna-3.2:\n",
      "      Successfully uninstalled idna-3.2\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 35.0.0\n",
      "    Uninstalling cryptography-35.0.0:\n",
      "      Successfully uninstalled cryptography-35.0.0\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.2.1\n",
      "    Uninstalling soupsieve-2.2.1:\n",
      "      Successfully uninstalled soupsieve-2.2.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.4\n",
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.4\n",
      "    Uninstalling pandas-1.3.4:\n",
      "      Successfully uninstalled pandas-1.3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\u001b[0m\n",
      "Successfully installed Flask-2.0.2 Jinja2-3.0.3 Werkzeug-2.0.2 brotli-1.0.9 bs4-0.0.1 cffi-1.15.0 charset-normalizer-2.0.8 cryptography-36.0.0 dash-2.0.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-compress-1.10.1 gunicorn-20.1.0 h11-0.12.0 idna-3.3 itsdangerous-2.0.1 numpy-1.21.2 outcome-1.1.0 pandas-1.2.1 plotly-5.3.1 pycparser-2.21 selenium-4.1.0 sniffio-1.2.0 sortedcontainers-2.4.0 soupsieve-2.3.1 tenacity-8.0.1 trio-0.19.0 trio-websocket-0.9.2 wsproto-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ../requirements.txt # Assumes this is being ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Selenium for use\n",
    "\n",
    "Requires we have a chromedriver executable. A \"setup_selenium.sh\" has been provided which downloads chromedriver executable for **linux** systems. If you're running this on another, please download the version 95 for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztiqJEv47qDC",
    "outputId": "a30759ee-acad-43c6-ba7e-69fbdbd348d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, json, requests\n",
    "from time import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import InvalidURL, SSLError, ConnectionError\n",
    "from urllib3.exceptions import NewConnectionError, LocationParseError\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "from IPython.display import clear_output \n",
    "MAX_RUN_TIME=480 # 480seconds = 8 minutes max runtime per hospital\n",
    "#MAX_RUN_TIME=120\n",
    "visited_urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCZjseYv792r"
   },
   "source": [
    "# Loading in the JSON file from the Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b78uea8J7y8f",
    "outputId": "12dc37f8-35a9-4428-b990-3424985d9c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arbor Health': {'wsha_url': 'https://www.wsha.org/members/morton-general-hospital', 'hospital_url': 'http://www.mortongeneral.org', 'county': 'Lewis', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '20', 'scraped_cdm': True}, 'Astria Sunnyside Hospital': {'wsha_url': 'https://www.wsha.org/members/sunnyside-community-hospital-clinics', 'hospital_url': 'https://www.astria.health/locations/astria-sunnyside-hospital', 'county': 'Yakima', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '15', 'scraped_cdm': True}, 'Astria Toppenish Hospital': {'wsha_url': 'https://www.wsha.org/members/toppenish-community-hospital', 'hospital_url': 'https://www.astria.health/locations/astria-toppenish-hospital', 'county': 'Yakima', 'nbeds': 48, 'congressional_district': '4', 'legislative_district': '15', 'scraped_cdm': True}, 'Cascade Behavioral Health': {'wsha_url': 'https://www.wsha.org/members/cascade-behavioral-health', 'hospital_url': 'https://www.cascadebh.com/admissions/insurance-payment-information/rates-pricing/', 'county': 'King', 'nbeds': 137, 'congressional_district': '9', 'legislative_district': '11,33,34,47', 'scraped_cdm': True}, 'Cascade Medical': {'wsha_url': 'https://www.wsha.org/members/cascade-medical-center', 'hospital_url': 'https://cascademedical.org/patient-resources/billing', 'county': 'Chelan', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '12', 'scraped_cdm': True}, 'Cascade Valley Hospital and Clinics': {'wsha_url': 'https://www.wsha.org/members/cascade-valley-hospital-and-clinics', 'hospital_url': 'http://www.cascadevalley.org', 'county': 'Snohomish', 'nbeds': 48, 'congressional_district': '2', 'legislative_district': '10,39', 'scraped_cdm': True}, 'Columbia Basin Hospital': {'wsha_url': 'https://www.wsha.org/members/columbia-basin-hospital', 'hospital_url': 'http://www.columbiabasinhospital.org', 'county': 'Grant', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '12,13', 'scraped_cdm': True}, 'Columbia County Health System': {'wsha_url': 'https://www.wsha.org/members/columbia-county-health-system', 'hospital_url': 'http://www.cchd-wa.org', 'county': 'Columbia', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '16', 'scraped_cdm': False, 'cdm_missing': True}, 'Confluence Health': {'wsha_url': 'https://www.wsha.org/members/confluence-health', 'hospital_url': 'https://www.confluencehealth.org/patient-information/billing-insurance-information/hospital-pricing-transparency/', 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': True}, 'Confluence Health/Central Washington Hospital': {'wsha_url': 'https://www.wsha.org/members/confluence-healthcentral-washington-hospital-2', 'hospital_url': 'http://www.confluencehealth.org', 'county': 'Chelan', 'nbeds': 198, 'congressional_district': '8', 'legislative_district': '12,13', 'scraped_cdm': True}, 'Confluence Health/Wenatchee Valley Hospital &amp; Clinics': {'wsha_url': 'https://www.wsha.org/members/confluence-healthwenatchee-valley-hospital', 'hospital_url': 'http://www.confluencehealth.org', 'county': 'Chelan', 'nbeds': 20, 'congressional_district': '8', 'legislative_district': '12', 'scraped_cdm': True}, 'Coulee Medical Center': {'wsha_url': 'https://www.wsha.org/members/coulee-medical-center', 'hospital_url': 'http://www.cmccares.org', 'county': 'Grant', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '12,13', 'scraped_cdm': True}, 'East Adams Rural Healthcare': {'wsha_url': 'https://www.wsha.org/members/east-adams-rural-healthcare', 'hospital_url': 'https://www.earh.org/', 'county': 'Adams', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '9', 'scraped_cdm': True}, 'Eastern State Hospital': {'wsha_url': 'https://www.wsha.org/members/eastern-state-hospital', 'hospital_url': 'https://www.dshs.wa.gov/bhsia/division-state-hospitals/eastern-state-hospital-overview', 'county': 'Spokane', 'nbeds': 317, 'congressional_district': '5', 'legislative_district': '6', 'scraped_cdm': True}, 'EvergreenHealth': {'wsha_url': 'https://www.wsha.org/members/evergreenhealth', 'hospital_url': 'https://www.evergreenhealth.com/patients-visitors/billing-financial/cost-estimate-ehk/', 'county': 'King', 'nbeds': 318, 'congressional_district': '1', 'legislative_district': '1, 45, 48', 'scraped_cdm': True}, 'EvergreenHealth Monroe': {'wsha_url': 'https://www.wsha.org/members/evergreenhealth-monroe', 'hospital_url': 'https://www.evergreenhealth.com/ehm/patients-visitors/cost-estimate-ehm/', 'county': 'Snohomish', 'nbeds': 35, 'congressional_district': '1', 'legislative_district': '39', 'scraped_cdm': True}, 'Fairfax Behavioral Health Everett': {'wsha_url': 'https://www.wsha.org/members/fairfax-behavioral-health-everett', 'hospital_url': 'https://www.inova.org/patient-and-visitor-information/hospital-charges', 'county': 'Snohomish', 'nbeds': None, 'congressional_district': '2', 'legislative_district': '38', 'scraped_cdm': True}, 'Fairfax Behavioral Health Kirkland': {'wsha_url': 'https://www.wsha.org/members/fairfax-hospital', 'hospital_url': 'http://www.fairfaxhospital.com', 'county': 'King', 'nbeds': 221, 'congressional_district': '1', 'legislative_district': '1,45,48', 'scraped_cdm': True}, 'Fairfax Behavioral Health Monroe': {'wsha_url': 'https://www.wsha.org/members/fairfax-behavioral-health-monroe', 'hospital_url': 'https://www.fairfaxhospital.com/', 'county': 'Snohomish', 'nbeds': None, 'congressional_district': '1', 'legislative_district': '39', 'scraped_cdm': True}, 'Ferry County Health': {'wsha_url': 'https://www.wsha.org/members/ferry-county-memorial-hospital', 'hospital_url': 'http://www.fcphd.org', 'county': 'Ferry', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False, 'cdm_missing': True}, 'Forks Community Hospital': {'wsha_url': 'https://www.wsha.org/members/forks-community-hospital', 'hospital_url': 'http://www.forkshospital.org', 'county': 'Clallam', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': True}, 'Garfield County Hospital District': {'wsha_url': 'https://www.wsha.org/members/garfield-county-public-hospital-district', 'hospital_url': 'http://www.pomeroymd.com', 'county': 'Garfield', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Harbor Regional Health': {'wsha_url': 'https://www.wsha.org/members/grays-harbor-community-hospital', 'hospital_url': 'http://www.ghcares.org/', 'county': 'Grays Harbor', 'nbeds': 105, 'congressional_district': '6', 'legislative_district': '19,24', 'scraped_cdm': False}, 'Inland Northwest Behavioral Health': {'wsha_url': 'https://www.wsha.org/members/inland-northwest-behavioral-health', 'hospital_url': 'https://inlandnorthwestbh.com/', 'county': 'Spokane', 'nbeds': 100, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Island Hospital': {'wsha_url': 'https://www.wsha.org/members/island-hospital', 'hospital_url': 'http://www.islandhospital.org', 'county': 'Skagit', 'nbeds': 43, 'congressional_district': '2', 'legislative_district': '40,10', 'scraped_cdm': False}, 'Jefferson Healthcare': {'wsha_url': 'https://www.wsha.org/members/jefferson-healthcare', 'hospital_url': 'http://www.jeffersonhealthcare.org', 'county': 'Jefferson', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': True}, 'Kadlec Regional Medical Center': {'wsha_url': 'https://www.wsha.org/members/kadlec-regional-medical-center', 'hospital_url': 'http://www.kadlec.org', 'county': 'Benton', 'nbeds': 270, 'congressional_district': '4', 'legislative_district': '8,9,16', 'scraped_cdm': False}, 'Kaiser Foundation Health Plan of Washington': {'wsha_url': 'https://www.wsha.org/members/kaiser-foundation-health-plan-washington', 'hospital_url': 'http://www.kp.org/wa', 'county': 'King', 'nbeds': 15, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Kindred Hospital Seattle – First Hill': {'wsha_url': 'https://www.wsha.org/members/kindred-hospital-seattle-first-hill', 'hospital_url': 'http://www.kindredhealthcare.com', 'county': 'King', 'nbeds': 50, 'congressional_district': '7', 'legislative_district': '43', 'scraped_cdm': False}, 'Kittitas Valley Healthcare': {'wsha_url': 'https://www.wsha.org/members/kittitas-valley-healthcare', 'hospital_url': 'http://www.kvhealthcare.org', 'county': 'Kittitas', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '13', 'scraped_cdm': False}, 'Klickitat Valley Health': {'wsha_url': 'https://www.wsha.org/members/klickitat-valley-health', 'hospital_url': 'http://www.kvhealth.net', 'county': 'Klickitat', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '14', 'scraped_cdm': False}, 'Lake Chelan Health': {'wsha_url': 'https://www.wsha.org/members/lake-chelan-community-hospital', 'hospital_url': 'http://www.lakechelancommunityhospital.com', 'county': 'Chelan', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '12', 'scraped_cdm': False}, 'Legacy Health': {'wsha_url': 'https://www.wsha.org/members/legacy-health', 'hospital_url': 'http://www.legacyhealth.org', 'county': None, 'nbeds': None, 'congressional_district': '3', 'legislative_district': '17,18,49', 'scraped_cdm': False}, 'Legacy Salmon Creek Medical Center': {'wsha_url': 'https://www.wsha.org/members/legacy-salmon-creek-medical-center', 'hospital_url': 'http://www.legacyhealth.org', 'county': 'Clark', 'nbeds': 220, 'congressional_district': '3', 'legislative_district': '17,18,49', 'scraped_cdm': False}, 'Lincoln Hospital': {'wsha_url': 'https://www.wsha.org/members/lincoln-hospital', 'hospital_url': 'http://www.lincolnhospital.org', 'county': 'Lincoln', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '13', 'scraped_cdm': False}, 'Lourdes Counseling Center': {'wsha_url': 'https://www.wsha.org/members/lourdes-counseling-center', 'hospital_url': 'http://www.lourdeshealth.net', 'county': 'Benton', 'nbeds': 44, 'congressional_district': '4', 'legislative_district': '8,16', 'scraped_cdm': False}, 'Lourdes Health': {'wsha_url': 'https://www.wsha.org/members/lourdes-medical-center', 'hospital_url': 'http://www.lourdeshealth.net', 'county': 'Franklin', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '8,16', 'scraped_cdm': False}, 'Madigan Army Medical Center': {'wsha_url': 'https://www.wsha.org/members/madigan-army-medical-center', 'hospital_url': 'http://www.mamc.amedd.army.mil', 'county': 'Pierce', 'nbeds': 240, 'congressional_district': '10', 'legislative_district': '28', 'scraped_cdm': False}, 'Mason Health': {'wsha_url': 'https://www.wsha.org/members/mason-general-hospital-family-of-clinics', 'hospital_url': 'http://www.masongeneral.com', 'county': 'Mason', 'nbeds': 25, 'congressional_district': '10', 'legislative_district': '35', 'scraped_cdm': False}, 'Mid-Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/mid-valley-hospital', 'hospital_url': 'http://www.mvhealth.org', 'county': 'Okanogan', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '7,12', 'scraped_cdm': False}, 'MultiCare Allenmore Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-allenmore-hospital', 'hospital_url': 'http://www.multicare.org/allenmore', 'county': 'Pierce', 'nbeds': 70, 'congressional_district': '6', 'legislative_district': '25,26,27,28,29', 'scraped_cdm': False}, 'MultiCare Auburn Medical Center': {'wsha_url': 'https://www.wsha.org/members/multicare-auburn-medical-center', 'hospital_url': 'http://www.multicare.org/auburnmedical', 'county': 'King', 'nbeds': 195, 'congressional_district': '8', 'legislative_district': '30, 47', 'scraped_cdm': False}, 'MultiCare Capital Medical Center': {'wsha_url': 'https://www.wsha.org/members/capital-medical-center', 'hospital_url': 'http://www.capitalmedical.com', 'county': 'Thurston', 'nbeds': 107, 'congressional_district': '10', 'legislative_district': '20,22', 'scraped_cdm': False}, 'MultiCare Covington Medical Center': {'wsha_url': 'https://www.wsha.org/members/multicare-covington-medical-center', 'hospital_url': 'https://www.multicare.org/covington-medical-center/?utm_source=google&amp;utm_medium=organic&amp;utm_campaign=local', 'county': 'Pierce', 'nbeds': 58, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'MultiCare Deaconess Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-deaconess-hospital', 'hospital_url': 'https://www.multicare.org/deaconess-hospital/', 'county': 'Spokane', 'nbeds': 388, 'congressional_district': '5', 'legislative_district': '3,6', 'scraped_cdm': False}, 'MultiCare Good Samaritan  Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-good-samaritan-hospital', 'hospital_url': 'http://www.multicare.org/goodsam', 'county': 'Pierce', 'nbeds': 286, 'congressional_district': '10', 'legislative_district': '2,25,31', 'scraped_cdm': False}, 'MultiCare Health System': {'wsha_url': 'https://www.wsha.org/members/multicare-health-system', 'hospital_url': 'http://www.multicare.org', 'county': 'Pierce', 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'MultiCare Mary Bridge Children’s Hospital &amp; Health Center': {'wsha_url': 'https://www.wsha.org/members/multicare-mary-bridge-childrens-hospital-health-center', 'hospital_url': 'http://www.multicare.org/marybridge', 'county': 'Pierce', 'nbeds': 82, 'congressional_district': '6', 'legislative_district': '25,26,27,28,29', 'scraped_cdm': False}, 'MultiCare Tacoma General Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-tacoma-general-hospital', 'hospital_url': 'http://www.multicare.org/tacomageneral', 'county': 'Pierce', 'nbeds': 567, 'congressional_district': '6', 'legislative_district': '25,27,28,29', 'scraped_cdm': False}, 'MultiCare Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-valley-hospital', 'hospital_url': 'https://www.multicare.org/valley-hospital/', 'county': 'Spokane', 'nbeds': 123, 'congressional_district': '5', 'legislative_district': '4', 'scraped_cdm': False}, 'MultiMedical Systems': {'wsha_url': 'https://www.wsha.org/members/multimedical-systems', 'hospital_url': None, 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Naval Hospital': {'wsha_url': 'https://www.wsha.org/members/naval-hospital', 'hospital_url': 'https://bremerton.tricare.mil', 'county': 'Kitsap', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '35', 'scraped_cdm': False}, 'Navos': {'wsha_url': 'https://www.wsha.org/members/navos', 'hospital_url': 'http://www.navos.org', 'county': 'King', 'nbeds': 43, 'congressional_district': '7', 'legislative_district': '34', 'scraped_cdm': False}, 'Newport Hospital &amp; Health Services': {'wsha_url': 'https://www.wsha.org/members/newport-hospital-health-services', 'hospital_url': 'http://newporthospitalandhealth.org/', 'county': 'Pend Oreille', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False}, 'North Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/north-valley-hospital', 'hospital_url': 'http://www.nvhospital.org', 'county': 'Okanogan', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '7', 'scraped_cdm': False}, 'Ocean Beach Hospital &amp; Medical Clinics': {'wsha_url': 'https://www.wsha.org/members/ocean-beach-hospital', 'hospital_url': 'http://www.oceanbeachhospital.com', 'county': 'Pacific', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '19', 'scraped_cdm': False}, 'Odessa Memorial Healthcare Center': {'wsha_url': 'https://www.wsha.org/members/odessa-memorial-healthcare-center', 'hospital_url': 'http://www.omhc.org', 'county': 'Lincoln', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '13', 'scraped_cdm': False}, 'Olympic Medical Center': {'wsha_url': 'https://www.wsha.org/members/olympic-medical-center', 'hospital_url': 'http://www.olympicmedical.org', 'county': 'Clallam', 'nbeds': 126, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': False}, 'Othello Community Hospital': {'wsha_url': 'https://www.wsha.org/members/othello-community-hospital', 'hospital_url': 'http://www.othellocommunityhospital.org', 'county': 'Adams', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '9', 'scraped_cdm': False}, 'Overlake Medical Center': {'wsha_url': 'https://www.wsha.org/members/overlake-medical-center', 'hospital_url': 'http://www.overlakehospital.org', 'county': 'King', 'nbeds': 349, 'congressional_district': '9', 'legislative_district': '5,41,45,48', 'scraped_cdm': False}, 'PeaceHealth Peace Island Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-peace-island-medical-center', 'hospital_url': 'http://www.peacehealth.org/peace-island', 'county': 'San Juan', 'nbeds': 25, 'congressional_district': '2', 'legislative_district': '40', 'scraped_cdm': False}, 'PeaceHealth Southwest Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-southwest-medical-center', 'hospital_url': 'http://www.peacehealth.org/southwest', 'county': 'Clark', 'nbeds': 450, 'congressional_district': '3', 'legislative_district': '17,18,49', 'scraped_cdm': False}, 'PeaceHealth St. John Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-st-john-medical-center', 'hospital_url': 'http://www.peacehealth.org/st-john', 'county': 'Cowlitz', 'nbeds': 346, 'congressional_district': '3', 'legislative_district': '19,20', 'scraped_cdm': False}, 'PeaceHealth St. Joseph Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-st-joseph-medical-center', 'hospital_url': 'http://www.peacehealth.org/st-joseph', 'county': 'Whatcom', 'nbeds': 255, 'congressional_district': '2', 'legislative_district': '40,42', 'scraped_cdm': False}, 'PeaceHealth United General Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-united-general-medical-center', 'hospital_url': 'http://www.peacehealth.org/united-general', 'county': 'Skagit', 'nbeds': 25, 'congressional_district': '2', 'legislative_district': '39', 'scraped_cdm': False}, 'Prosser Memorial Health': {'wsha_url': 'https://www.wsha.org/members/pmh-medical-center', 'hospital_url': 'http://www.prosserhealth.org', 'county': 'Benton', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '16', 'scraped_cdm': False}, 'Providence Centralia Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-centralia-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/centralia-hospital', 'county': 'Lewis', 'nbeds': 128, 'congressional_district': '3', 'legislative_district': '7,19,20', 'scraped_cdm': False}, 'Providence Holy Family Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-holy-family-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/holy-family-hospital', 'county': 'Spokane', 'nbeds': 197, 'congressional_district': '5', 'legislative_district': '3,6', 'scraped_cdm': False}, 'Providence Mount Carmel Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-mount-carmel-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/mount-carmel-hospital', 'county': 'Stevens', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False}, 'Providence Regional Medical Center Everett': {'wsha_url': 'https://www.wsha.org/members/providence-regional-medical-center-everett', 'hospital_url': 'http://washington.providence.org/hospitals/regional-medical-center', 'county': 'Snohomish', 'nbeds': 530, 'congressional_district': '2', 'legislative_district': '10,21,38,39,44', 'scraped_cdm': False}, 'Providence Sacred Heart Medical Center &amp; Children’s Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-sacred-heart-medical-center-childrens-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/sacred-heart-medical-center-and-childrens-hospital', 'county': 'Spokane', 'nbeds': 691, 'congressional_district': '5', 'legislative_district': '3,4,6,7,9', 'scraped_cdm': False}, 'Providence St. Joseph’s Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-st-josephs-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/st-josephs-hospital', 'county': 'Stevens', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False}, 'Providence St. Mary Medical Center': {'wsha_url': 'https://www.wsha.org/members/providence-st-mary-medical-center', 'hospital_url': 'http://washington.providence.org/hospitals/st-mary', 'county': 'Walla Walla', 'nbeds': 142, 'congressional_district': '5', 'legislative_district': '8,16', 'scraped_cdm': False}, 'Providence St. Peter Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-st-peter-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/st-peter', 'county': 'Thurston', 'nbeds': 390, 'congressional_district': '10', 'legislative_district': '2,20,22,35', 'scraped_cdm': False}, 'Pullman Regional Hospital': {'wsha_url': 'https://www.wsha.org/members/pullman-regional-hospital', 'hospital_url': 'http://www.pullmanregional.org', 'county': 'Whitman', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Quincy Valley Medical Center': {'wsha_url': 'https://www.wsha.org/members/quincy-valley-medical-center', 'hospital_url': 'http://www.quincyhospital.org', 'county': 'Grant', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '13', 'scraped_cdm': False}, 'Rainier Springs': {'wsha_url': 'https://www.wsha.org/members/rainier-springs', 'hospital_url': 'https://rainiersprings.com/', 'county': 'Clark', 'nbeds': None, 'congressional_district': '3', 'legislative_district': '17', 'scraped_cdm': False}, 'Samaritan Healthcare': {'wsha_url': 'https://www.wsha.org/members/samaritan-healthcare', 'hospital_url': 'http://www.samaritanhealthcare.com', 'county': 'Grant', 'nbeds': 50, 'congressional_district': '4', 'legislative_district': '13', 'scraped_cdm': False}, 'Seattle Cancer Care Alliance': {'wsha_url': 'https://www.wsha.org/members/seattle-cancer-care-alliance', 'hospital_url': 'http://www.seattlecca.org', 'county': 'King', 'nbeds': 20, 'congressional_district': '7', 'legislative_district': '23, 32, 33, 34, 36, 37, 41, 43, 45, 46, 48', 'scraped_cdm': False}, 'Seattle Children’s': {'wsha_url': 'https://www.wsha.org/members/seattle-childrens', 'hospital_url': 'http://www.seattlechildrens.org', 'county': 'King', 'nbeds': 407, 'congressional_district': '7', 'legislative_district': '32, 33, 36, 41, 43, 48', 'scraped_cdm': False}, 'Shriners Hospitals for Children – Spokane': {'wsha_url': 'https://www.wsha.org/members/shriners-hospitals-for-children-spokane', 'hospital_url': 'http://www.shrinershospitalsforchildren.org/Locations/spokane', 'county': 'Spokane', 'nbeds': 69, 'congressional_district': '5', 'legislative_district': '3', 'scraped_cdm': False}, 'Skagit Regional Health': {'wsha_url': 'https://www.wsha.org/members/skagit-regional-health', 'hospital_url': 'http://www.skagitregionalhealth.org', 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Skagit Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/skagit-valley-hospital', 'hospital_url': 'http://www.skagitregionalhealth.org/locations/skagit-valley-hospital', 'county': 'Skagit', 'nbeds': 173, 'congressional_district': '1', 'legislative_district': '10,40', 'scraped_cdm': False}, 'Skyline Health': {'wsha_url': 'https://www.wsha.org/members/skyline-hospital', 'hospital_url': 'http://www.myskylinehealth.org', 'county': 'Klickitat', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '14', 'scraped_cdm': False}, 'Smokey Point Behavioral Hospital': {'wsha_url': 'https://www.wsha.org/members/smokey-point-behavioral-hospital', 'hospital_url': 'http://www.smokeypointbehavioralhospital.com', 'county': 'Snohomish', 'nbeds': 115, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Snoqualmie Valley Hospital District': {'wsha_url': 'https://www.wsha.org/members/snoqualmie-valley-hospital-district', 'hospital_url': 'http://www.snoqualmiehospital.org', 'county': 'King', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '5', 'scraped_cdm': False}, 'South Sound Behavioral Hospital': {'wsha_url': 'https://www.wsha.org/members/south-sound-behavioral-hospital', 'hospital_url': 'https://www.southsoundbehavioralhospital.com/', 'county': 'Thurston', 'nbeds': None, 'congressional_district': '10', 'legislative_district': '22', 'scraped_cdm': False}, 'St. Anne Hospital': {'wsha_url': 'https://www.wsha.org/members/highline-medical-center', 'hospital_url': 'http://www.chifranciscan.org/highline-medical-center', 'county': 'King', 'nbeds': 133, 'congressional_district': '7', 'legislative_district': '11,33,34,47', 'scraped_cdm': False}, 'St. Anthony Hospital': {'wsha_url': 'https://www.wsha.org/members/st-anthony-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Anthony-Hospital/', 'county': 'Pierce', 'nbeds': 112, 'congressional_district': '6', 'legislative_district': '26', 'scraped_cdm': False}, 'St. Clare Hospital': {'wsha_url': 'https://www.wsha.org/members/st-clare-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Clare-Hospital/', 'county': 'Pierce', 'nbeds': 106, 'congressional_district': '10', 'legislative_district': '28,29', 'scraped_cdm': False}, 'St. Elizabeth Hospital': {'wsha_url': 'https://www.wsha.org/members/st-elizabeth-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Elizabeth-Hospital/', 'county': 'King', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '5,31', 'scraped_cdm': False}, 'St. Francis Hospital': {'wsha_url': 'https://www.wsha.org/members/st-francis-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Francis-Hospital/', 'county': 'King', 'nbeds': 124, 'congressional_district': '9', 'legislative_district': '30', 'scraped_cdm': False}, 'St. Joseph Medical Center': {'wsha_url': 'https://www.wsha.org/members/st-joseph-medical-center', 'hospital_url': 'http://www.chifranciscan.org/St-Joseph-Medical-Center/', 'county': 'Pierce', 'nbeds': 366, 'congressional_district': '6', 'legislative_district': '25, 27, 28, 29', 'scraped_cdm': False}, 'St. Luke’s Rehabilitation Institute': {'wsha_url': 'https://www.wsha.org/members/st-lukes-rehabilitation-institute', 'hospital_url': 'http://www.st-lukes.org', 'county': 'Spokane', 'nbeds': 102, 'congressional_district': '5', 'legislative_district': '3,4,6', 'scraped_cdm': False}, 'St. Michael Medical Center': {'wsha_url': 'https://www.wsha.org/members/harrison-medical-center', 'hospital_url': 'http://www.harrisonmedical.org', 'county': 'Kitsap', 'nbeds': 260, 'congressional_district': '6', 'legislative_district': '23,26,35', 'scraped_cdm': False}, 'Summit Pacific Medical Center': {'wsha_url': 'https://www.wsha.org/members/summit-pacific-medical-center', 'hospital_url': 'http://www.summitpacificmedicalcenter.org/', 'county': 'Grays Harbor', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': False}, 'Swedish Ballard': {'wsha_url': 'https://www.wsha.org/members/swedish-ballard', 'hospital_url': 'http://www.swedish.org/locations/ballard-campus', 'county': 'King', 'nbeds': 75, 'congressional_district': '7', 'legislative_district': '32,36,43,46', 'scraped_cdm': False}, 'Swedish Cherry Hill': {'wsha_url': 'https://www.wsha.org/members/swedish-cherry-hill', 'hospital_url': 'http://www.swedish.org/locations/cherry-hill-campus', 'county': 'King', 'nbeds': 227, 'congressional_district': '9', 'legislative_district': '11,34,36,37,41,43,46', 'scraped_cdm': False}, 'Swedish Edmonds': {'wsha_url': 'https://www.wsha.org/members/swedish-edmonds', 'hospital_url': 'http://www.swedish.org/locations/edmonds-campus', 'county': 'Snohomish', 'nbeds': 186, 'congressional_district': '7', 'legislative_district': '1,21,32', 'scraped_cdm': False}, 'Swedish First Hill': {'wsha_url': 'https://www.wsha.org/members/swedish-first-hill', 'hospital_url': 'http://www.swedish.org/locations/first-hill-campus', 'county': 'King', 'nbeds': 637, 'congressional_district': '9', 'legislative_district': '11,34,36,41,43,46', 'scraped_cdm': False}, 'Swedish Health Services': {'wsha_url': 'https://www.wsha.org/members/swedish-health-services', 'hospital_url': 'http://www.swedish.org', 'county': 'King', 'nbeds': None, 'congressional_district': '7', 'legislative_district': '1, 5, 11, 21, 32, 34, 36, 37, 41, 43, 45, 46, 48', 'scraped_cdm': False}, 'Swedish Issaquah': {'wsha_url': 'https://www.wsha.org/members/swedish-issaquah', 'hospital_url': 'http://www.swedish.org/locations/issaquah-campus', 'county': 'King', 'nbeds': 144, 'congressional_district': '8', 'legislative_district': '5,41,45,48', 'scraped_cdm': False}, 'Three Rivers Hospital': {'wsha_url': 'https://www.wsha.org/members/three-rivers-hospital', 'hospital_url': 'http://www.threerivershospital.net', 'county': 'Okanogan/Douglas', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '12', 'scraped_cdm': False}, 'Tri-State Memorial Hospital': {'wsha_url': 'https://www.wsha.org/members/tri-state-memorial-hospital', 'hospital_url': 'http://www.tristatehospital.org', 'county': 'Asotin', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Trios Health': {'wsha_url': 'https://www.wsha.org/members/trios-health', 'hospital_url': 'http://www.trioshealth.org', 'county': 'Benton', 'nbeds': 124, 'congressional_district': '4', 'legislative_district': '8,16', 'scraped_cdm': False}, 'UW Medical Center Montlake &amp; Northwest': {'wsha_url': 'https://www.wsha.org/members/uw-medicinenorthwest-hospital-medical-center', 'hospital_url': 'http://www.uwmedicine.org/northwest-hospital', 'county': 'King', 'nbeds': 281, 'congressional_district': '7', 'legislative_district': '32,36,43,46', 'scraped_cdm': False}, 'UW Medicine': {'wsha_url': 'https://www.wsha.org/members/uw-medicine', 'hospital_url': 'http://www.uwmedicine.org', 'county': 'King', 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'UW Medicine/Harborview Medical Center': {'wsha_url': 'https://www.wsha.org/members/uw-medicineharborview-medical-center', 'hospital_url': 'http://www.uwmedicine.org/harborview', 'county': 'King', 'nbeds': 413, 'congressional_district': '9', 'legislative_district': '11, 32, 34, 36, 37, 41, 43, 46', 'scraped_cdm': False}, 'UW Medicine/University of Washington Medical Center': {'wsha_url': 'https://www.wsha.org/members/uw-medicineuniversity-of-washington-medical-center', 'hospital_url': 'http://www.uwmedicine.org/uw-medical-center', 'county': 'King', 'nbeds': 473, 'congressional_district': '7', 'legislative_district': '32,34,36,37,41,43,46', 'scraped_cdm': False}, 'UW Medicine/Valley Medical Center': {'wsha_url': 'https://www.wsha.org/members/uw-medicinevalley-medical-center', 'hospital_url': 'http://www.uwmedicine.org/valley-medical-center', 'county': 'King', 'nbeds': 321, 'congressional_district': '9', 'legislative_district': '11,33,34,47', 'scraped_cdm': False}, 'VA Puget Sound Health Care System': {'wsha_url': 'https://www.wsha.org/members/va-puget-sound-health-care-system-tacoma', 'hospital_url': 'http://www.pugetsound.va.gov', 'county': 'King', 'nbeds': 459, 'congressional_district': '9', 'legislative_district': '28', 'scraped_cdm': False}, 'Virginia Mason Franciscan Health': {'wsha_url': 'https://www.wsha.org/members/chi-franciscan-health', 'hospital_url': 'https://www.innovativecareahead.org/', 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Virginia Mason Medical Center': {'wsha_url': 'https://www.wsha.org/members/virginia-mason-medical-center', 'hospital_url': 'http://www.virginiamason.org', 'county': 'King', 'nbeds': 371, 'congressional_district': '7', 'legislative_district': '11, 34, 36, 37, 43, 46', 'scraped_cdm': False}, 'Wellfound Behavioral Health Hospital': {'wsha_url': 'https://www.wsha.org/members/wellfound-behavioral-health-hospital', 'hospital_url': 'https://www.wellfound.org/', 'county': 'Pierce', 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Western State Hospital': {'wsha_url': 'https://www.wsha.org/members/western-state-hospital', 'hospital_url': 'http://www.dshs.wa.gov/bha/division-state-hospitals/western-state-hospital', 'county': 'Pierce', 'nbeds': 771, 'congressional_district': '10', 'legislative_district': '28', 'scraped_cdm': False}, 'WhidbeyHealth': {'wsha_url': 'https://www.wsha.org/members/whidbeygeneralhospital', 'hospital_url': 'https://whidbeyhealth.org/', 'county': 'Island', 'nbeds': 25, 'congressional_district': '2', 'legislative_district': '10', 'scraped_cdm': False}, 'Whitman Hospital and Medical Clinics': {'wsha_url': 'https://www.wsha.org/members/whitman-hospital-and-medical-center', 'hospital_url': 'http://www.whitmanhospital.com', 'county': 'Whitman', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Willapa Harbor Hospital': {'wsha_url': 'https://www.wsha.org/members/willapa-harbor-hospital', 'hospital_url': 'http://www.willapaharborhospital.com', 'county': 'Pacific', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '19', 'scraped_cdm': False}, 'Yakima Valley Memorial': {'wsha_url': 'https://www.wsha.org/members/virginia-mason-memorial-hospital', 'hospital_url': 'http://www.yakimamemorialhospital.org', 'county': 'Yakima', 'nbeds': 226, 'congressional_district': '4', 'legislative_district': '13,14,15', 'scraped_cdm': False}}\n"
     ]
    }
   ],
   "source": [
    "URLS_PATH = \"/content/drive/MyDrive/CSE583_ChargeMaster/ChargeMaster_Data_Aggregator-main/data/hospital_urls.json\"\n",
    "hospital_urls = json.load(open(URLS_PATH))\n",
    "print(hospital_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhKTND3A8AwB"
   },
   "source": [
    "# Beginning Web Crawling\n",
    "\n",
    "Code for the web crawler/scraper itself\n",
    "\n",
    "## \"Blacklist\" websites\n",
    "Many hospitals have external links to linkedin, news articles about them, facebook, etc. and obviously we don't want the scraper to go there. So we defined a blacklist of domains that the scraper should avoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cuB-bKjTxKl"
   },
   "outputs": [],
   "source": [
    "blacklist = ['facebook',\n",
    "             'yahoo',\n",
    "             'gmail',\n",
    "             'google', \n",
    "             'linkedin',\n",
    "             'javascript',\n",
    "             'javascript;',\n",
    "             'javascript:;',\n",
    "             'youtube',\n",
    "             'twitter',\n",
    "             'tiktok',\n",
    "             'cdc',\n",
    "             'mailto',\n",
    "             'nih.gov',\n",
    "             'coronavirus.gov',\n",
    "             'usa.gov',\n",
    "             'youtube',\n",
    "             'instagram',\n",
    "             'doh',\n",
    "             'aboutus',\n",
    "             'about-us',\n",
    "             'news',\n",
    "             'employment',\n",
    "             'mailto',\n",
    "             'covid19', \n",
    "             'covid-19',\n",
    "             'covid_19',\n",
    "             '.gov',\n",
    "             'dhs',\n",
    "             'tel:+',\n",
    "             '#content',\n",
    "             '#main',\n",
    "             'about',\n",
    "             'granthealth'\n",
    "             'forgot', \n",
    "             'password',\n",
    "             'goo.gl',\n",
    "             'tel:',\n",
    "             'apple.com',\n",
    "             'microsoft',\n",
    "             'mozilla',\n",
    "             'contactus',\n",
    "             'contactUs',\n",
    "             'ContactUs',\n",
    "             'tumblr',\n",
    "             'whatsapp',\n",
    "             'youtu',\n",
    "             'vimeo',\n",
    "             'search',\n",
    "             'wa',\n",
    "             'millcreek',\n",
    "             'gift',\n",
    "             'fchn',\n",
    "             'cellnetix',\n",
    "             'merchant',\n",
    "             'cuisine',\n",
    "             'office',\n",
    "             'flickr'\n",
    "             ]\n",
    "\"\"\"\n",
    "Adds to the list if any of the elements of \"blacklist\" are contained within url\n",
    "so if the list is non-empty, it contains a blacklist site. Returns if it contains\n",
    "a blacklist site or not. \n",
    "\"\"\"\n",
    "def is_blacklist(url):\n",
    "  blist = [site for site in blacklist if (site in url)]\n",
    "  is_blacklisted = len(blist) > 0 \n",
    "  return is_blacklisted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vKTRbYQb6mR"
   },
   "source": [
    "## Selenium\n",
    "\n",
    "Need to utilize Selenium to interact with the webpages. BeautifulSoup to crawl while using Seleniuim to interact with JS elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xR59USQncCHS"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5c6zDfg1LLf"
   },
   "outputs": [],
   "source": [
    "wd.quit()\n",
    "wd = webdriver.Chrome('chromedriver', options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsNN_CCvwM9d"
   },
   "source": [
    "Following cells were for testing selenium. Do not need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxKiQMvSdXbD"
   },
   "outputs": [],
   "source": [
    "wd.get('https://apps.para-hcfs.com/PTT/FinalLinks/ArborHealth_V3.aspx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvBIpE-luD9c"
   },
   "outputs": [],
   "source": [
    "elems = wd.find_elements(By.XPATH, \"//*[@onclick]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c16RjsrSvJ14"
   },
   "outputs": [],
   "source": [
    "elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "of3iCf6deHxn"
   },
   "outputs": [],
   "source": [
    "for elem in elems:\n",
    "  try:\n",
    "    print(elem)\n",
    "    elem.click()\n",
    "  except:\n",
    "    continue\n",
    "  #elems.get_attribute('onclick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb7KwxfrcCes"
   },
   "source": [
    "## Requests & Iterating Through Hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0WszNPR85qZ"
   },
   "outputs": [],
   "source": [
    "USER_AGENT = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
    "HEADERS = {'User-Agent': USER_AGENT}\n",
    "\"\"\"\n",
    "Didn't foresee that exception handling for just making the HTTP request would be\n",
    "this difficult to track down. Broke apart the web crawler into two parts, one\n",
    "for making the request and handling the HTTP status codes and one to parse\n",
    "the actual HTML returned. \n",
    "\"\"\"\n",
    "def get_request(hospital_name=None, url=None):\n",
    "  if not hospital_name or not url: return\n",
    "  req = None\n",
    "  try:\n",
    "    req = requests.get(url, headers=HEADERS)\n",
    "  except (InvalidURL, ConnectionError):\n",
    "    print(f\"Invalid URL: {url}, Hospital: {hospital_name}\")\n",
    "    try:\n",
    "      req = requests.get(url, verify=False, headers=HEADERS)\n",
    "    except: return\n",
    "  except (SSLError):\n",
    "    req = requests.get(url, verify=False, headers=HEADERS)\n",
    "    \"\"\"\n",
    "    Not doing 400s and 500s. Fiddling with headers still won't let me access some sites. \n",
    "    400s are usually invalid urls that are outdated. \n",
    "    Majority of the urls are still valid and return 200. \n",
    "    \"\"\"\n",
    "  if req.status_code >= 400: return None \n",
    "  return req\n",
    "  #print(f\"Response Code: {req.status_code}, hospital url: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbzAMArzjMAY"
   },
   "source": [
    "# Code to Check if link is downloadable\n",
    "Taken from https://www.codementor.io/@aviaryan/downloading-files-from-urls-in-python-77q3bs0un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMhspbRGjPTP"
   },
   "outputs": [],
   "source": [
    "def is_downloadable(url):\n",
    "    \"\"\"\n",
    "    Does the url contain a downloadable resource\n",
    "    \"\"\"\n",
    "    try:\n",
    "      h = requests.head(url, allow_redirects=True)\n",
    "    except:\n",
    "      return False\n",
    "    header = h.headers\n",
    "    content_type = header.get('content-type')\n",
    "    if 'text' in content_type.lower():\n",
    "        return False\n",
    "    if 'html' in content_type.lower():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AOYDlt3ToG2"
   },
   "source": [
    "# Selenium Handler\n",
    "Will allow us to click for any dynamically allocated content. E.g. a download onclick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZFOii_WyJDS"
   },
   "outputs": [],
   "source": [
    "from urllib3.exceptions import MaxRetryError\n",
    "from selenium.common.exceptions import ElementNotInteractableException, InvalidArgumentException\n",
    "\n",
    "def selenium_handle(url, time_diff):\n",
    "  print(f\"Selenium handling: {url}\")\n",
    "  if time_diff > MAX_RUN_TIME: return\n",
    "  #print(\"Selenium started\", time_diff)\n",
    "  wd = webdriver.Chrome('chromedriver', options=chrome_options)\n",
    "  try:\n",
    "    wd.get(url)\n",
    "  except (MaxRetryError, InvalidArgumentException): \n",
    "    wd.quit()\n",
    "    return\n",
    "\n",
    "  try:\n",
    "    elems = wd.find_elements(By.XPATH, \"//a[@onclick]\")\n",
    "    for elem in elems:\n",
    "      try:\n",
    "        print(f\"Found {str(elem)} onclick element\")\n",
    "        elem.click()\n",
    "      except ElementNotInteractableException: continue\n",
    "  except: \n",
    "    wd.quit()\n",
    "    return\n",
    "  wd.quit()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI3G9oWdzWuw"
   },
   "source": [
    "## Code to check if any hospital data has been downloaded\n",
    "Will check the working directory for any new files and move them to the subdirectory given. Moving files across file systems must be an atomic operation meaning that it is the only one run for the given process at a time. \n",
    "\n",
    "The code for this was taken from https://alexwlchan.net/2019/03/atomic-cross-filesystem-moves-in-python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENU3nVk4zcwL"
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# https://alexwlchan.net/2019/03/atomic-cross-filesystem-moves-in-python/\n",
    "def safe_move(src, dst):\n",
    "    \"\"\"Rename a file from ``src`` to ``dst``.\n",
    "\n",
    "    *   Moves must be atomic.  ``shutil.move()`` is not atomic.\n",
    "        Note that multiple threads may try to write to the cache at once,\n",
    "        so atomicity is required to ensure the serving on one thread doesn't\n",
    "        pick up a partially saved image from another thread.\n",
    "\n",
    "    *   Moves must work across filesystems.  Often temp directories and the\n",
    "        cache directories live on different filesystems.  ``os.rename()`` can\n",
    "        throw errors if run across filesystems.\n",
    "\n",
    "    So we try ``os.rename()``, but if we detect a cross-filesystem copy, we\n",
    "    switch to ``shutil.move()`` with some wrappers to make it atomic.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.rename(src, dst)\n",
    "    except OSError as err:\n",
    "\n",
    "        if err.errno == errno.EXDEV:\n",
    "            # Generate a unique ID, and copy `<src>` to the target directory\n",
    "            # with a temporary name `<dst>.<ID>.tmp`.  Because we're copying\n",
    "            # across a filesystem boundary, this initial copy may not be\n",
    "            # atomic.  We intersperse a random UUID so if different processes\n",
    "            # are copying into `<dst>`, they don't overlap in their tmp copies.\n",
    "            copy_id = uuid.uuid4()\n",
    "            tmp_dst = \"%s.%s.tmp\" % (dst, copy_id)\n",
    "            shutil.copyfile(src, tmp_dst)\n",
    "\n",
    "            # Then do an atomic rename onto the new name, and clean up the\n",
    "            # source image.\n",
    "            os.rename(tmp_dst, dst)\n",
    "            os.unlink(src)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "IGNORE_LIST = ['.config', 'drive', '.ipynb_checkpoints'] # Google Colab or Jupyter Notebook related files. Unrelated to scraped data\n",
    "\"\"\"\n",
    "ERROR: Cross file system transfers cannot be done with os.rename, os.replace\n",
    "Try using OS methods but if it doesn't work, use shuttil.move\n",
    "Needs to be atomic\n",
    "\"\"\"\n",
    "def check_and_move_files(SUBDIR_PATH=None):\n",
    "  if not SUBDIR_PATH: return\n",
    "  filenames = os.listdir(\".\")\n",
    "  for filename in filenames:\n",
    "    if filename in IGNORE_LIST: continue\n",
    "    safe_move(f\"./{filename}\", f\"{SUBDIR_PATH}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D0ZqkJGw95z"
   },
   "source": [
    "## Code to create a subdirectory for each hospital\n",
    "\n",
    "Each hospital will have its own subdirectory created to hold all files scraped. This will help us in organizing files since the scraper will most likely pick up other files along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGdjdtXHw8Ty"
   },
   "outputs": [],
   "source": [
    "SUBDIR_PATH = '/content/drive/MyDrive/CSE583_ChargeMaster/ChargeMaster_Data_Aggregator-main/data/scraped_data'\n",
    "#import re\n",
    "\"\"\"\n",
    "Just replace all whitespace in the name with a underscore (_) for file naming conventions.\n",
    "The names are taken from the WSHA page. We can assume they do not have any\n",
    "mistakes such as having whitespace in front of the name or behind.\n",
    "\n",
    "Will return the path of the subdirectory.\n",
    "\"\"\"\n",
    "def create_subdir(hospital_name):\n",
    "  hospital_name = hospital_name.strip()\n",
    "  subdir_name = hospital_name.replace(\" \", \"_\")\n",
    "  FULL_PATH = f\"{SUBDIR_PATH}/{subdir_name}\"\n",
    "  if not os.path.isdir(FULL_PATH): \n",
    "    os.mkdir(FULL_PATH)\n",
    "  return FULL_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTUed5kDfbmK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "WIP: IT DOES NOT WORK PROPERLY YET \n",
    "\n",
    "\n",
    "High Level Plan:\n",
    "1. Find all 'a' tags\n",
    "2. From the 'a' tags, get 'href's \n",
    "3. Comb through all hrefs for resources ending in 'csv' or 'xlsx' \n",
    "4. Else, the rest of the links are recursively called into web_crawl(same_hospital_name, new_link)\n",
    "\n",
    "Cases to look out for:\n",
    "1. Staying within the domain of the hospital\n",
    "1.1 This could be being redirected to their Facebook page instead. So...\n",
    "We want to check that the new URL we're visiting is a resource within the hospital's\n",
    "webpages.\n",
    "1.2 Can check for things like matching URLs. Evergreenhealth.org/patientportal is \n",
    "valid within Evergreenhealth but... Linkedin.com/Evergreenhealth isn't. \n",
    "\n",
    "\n",
    "Going to implement an x-levels deep search. From the main website, given 'x' levels,\n",
    "It'll search x subdomains deep. E.g. If x = 10, and it goes to let's say\n",
    "hopsitalwebsite.com/patients --> x = 9 now.  From here, it'll also search\n",
    "every url and each of those will go down 8 levels. It'll be a branching effect. \n",
    "\"\"\"\n",
    "visited_urls = []\n",
    "def web_crawl(hospital_name=None, hospital_url=None, url=None, level=1, starttime=-1):\n",
    "  if level == 0: return # Reached the extent of our search.\n",
    "  #if hospital_url not in url: return # Stay within the hospital domain. See note above\n",
    "  if url in visited_urls: return # Prevent circular crawling.\n",
    "  print(f\"Name: {hospital_name}, URL being parsed: {url}, {level} levels deep.\")\n",
    "  time_diff = time() - starttime\n",
    "  if time_diff > MAX_RUN_TIME: \n",
    "    print(\"TIME RUN OUT\")\n",
    "    return\n",
    "\n",
    "  try: # malformed url sometimes\n",
    "    page = get_request(hospital_name, url)\n",
    "  except requests.exceptions.InvalidSchema:\n",
    "    return\n",
    "  if not page: return\n",
    "  visited_urls.append(url)\n",
    "  soup = BeautifulSoup(page.content)\n",
    "  soup_html = str(soup)\n",
    "  downloadble_file = True\n",
    "  content_type = str(page.headers['content-type']).lower()\n",
    "  print(content_type)\n",
    "  if 'text' in content_type or 'html' in content_type:\n",
    "    downloadable_file = False\n",
    "  #downloadable_file\n",
    "  # SELENIUM HANDLER\n",
    "  if time() - starttime < MAX_RUN_TIME:\n",
    "    if 'onclick=' in soup_html or 'onclick =' in soup_html:\n",
    "      selenium_handle(url, time_diff)\n",
    "    \n",
    "  for a_href in soup.findAll('a'):\n",
    "    if time_diff > MAX_RUN_TIME: break\n",
    "    url = a_href.get('href')\n",
    "    if not url: continue\n",
    "    full_url = url\n",
    "    if 'http' not in url and 'https' not in url: \n",
    "      full_url = hospital_url + a_href.get('href')\n",
    "    if downloadble_file:\n",
    "      filename = full_url.split(\"/\")[-1]\n",
    "      try:\n",
    "        urlretrieve(full_url, f\"./{filename}\") # download with unique \n",
    "      except: continue\n",
    "    if not is_blacklist(full_url):\n",
    "      if time() - starttime < MAX_RUN_TIME:\n",
    "        web_crawl(hospital_name=hospital_name, hospital_url=hospital_url, url=full_url, level=level-1, starttime=starttime)\n",
    "      else: return\n",
    "    else:\n",
    "      continue\n",
    "    # TODO: If it ends in xlsx or csv, download, else recursively call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKGKJV541_s_",
    "outputId": "9e9fedd2-2575-46fa-f7ce-01af5e44db28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./asd', <http.client.HTTPMessage at 0x7f7f44e9a7d0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve('https://www.cascadebh.com/wp-content/uploads/pricing/cascade-2020-pricing.csv', './asd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFKVI84e_85"
   },
   "source": [
    "## Code for the Web Crawler + Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZIZYnzYwEmZS",
    "outputId": "f72c312e-2a4d-4d88-ab2c-716c10a6d03a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://cascademedical.org'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def get_domain(url):\n",
    "  pattern = '(http[s]?:\\/\\/([w]{3}\\.)?[a-zA-Z1-9]*\\.(org|com|net)).*'\n",
    "  match = re.match(pattern, url)\n",
    "  if match: return match.group(1)\n",
    "  return match\n",
    "\n",
    "get_domain('https://cascademedical.org/patient-resources/billing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggBhRaE2kTqv"
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "APX_KEYWORD = 'apps.para'\n",
    "\n",
    "def is_within_time(starttime): return time() - starttime < MAX_RUN_TIME\n",
    "\n",
    "def is_downloadable_link(page):\n",
    "  content_type = str(page.headers['content-type']).lower()\n",
    "  if 'text' in content_type or 'html' in content_type: \n",
    "    return False\n",
    "  return True\n",
    "\n",
    "def format_url(url, href):\n",
    "  full_url = \"\"\n",
    "  if 'http' not in href: # These are strict redirects. \n",
    "    if href.startswith(\".\"): return None\n",
    "    elif url.endswith(\"/\"): full_url = url + href\n",
    "    else: full_url = f\"{url}/{href}\"\n",
    "    full_url = full_url.replace(\"//\", \"/\")\n",
    "    if 'https:/' in full_url: full_url = full_url.replace(\"https:/\", \"https://\")\n",
    "    else: full_url = full_url.replace(\"http:/\", \"http://\")\n",
    "  else: \n",
    "    full_url = href\n",
    "  return full_url\n",
    "\n",
    "def url_format(url, href):\n",
    "  full_url = \"\"\n",
    "  if 'http' not in href:\n",
    "    if 'para' in href: print(href)\n",
    "    if not full_url.endswith(\"/\"): full_url = url + \"/\" \n",
    "    full_url = urljoin(full_url, href)\n",
    "  else: full_url = href\n",
    "  return full_url\n",
    "  \n",
    "\n",
    "def get_domain(url):\n",
    "  pattern = '(http[s]?:\\/\\/([w]{3}\\.)?[a-zA-Z1-9]*\\.(org|com|net)).*'\n",
    "  if type(url) != str: return None\n",
    "  match = re.match(pattern, url)\n",
    "  if match: return match.group(1)\n",
    "  return match\n",
    "\n",
    "def check_download(full_url, page):\n",
    "  if is_downloadable_link(page):\n",
    "    filename = full_url.split(\"/\")[-1]\n",
    "    print(f\"{filename} is downloadable\")\n",
    "    try:\n",
    "      urlretrieve(full_url, f\"./{filename}\") # download with unique \n",
    "    except: pass\n",
    "\n",
    "def check_selenium(soup, url, starttime):\n",
    "  soup_html = str(soup)\n",
    "  if 'onclick' in soup_html:\n",
    "    selenium_handle(url, time() - starttime)\n",
    "\n",
    "def check_for_csv_xlsx(url, href):\n",
    "  full_url = \"\"\n",
    "  if 'http' in href: full_url = href\n",
    "  else: full_url = url_format(url, href)\n",
    "  if full_url.endswith(\"csv\") or full_url.endswith(\"xlsx\"):\n",
    "    try:\n",
    "      filename = href.split(\"/\")[-1]\n",
    "      urlretrieve(alternative_link, f\"./{filename}\")\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "def check_for_csv_xlsx_files(hospital_name, hrefs, url, starttime, levels):\n",
    "  full_url = \"\"\n",
    "  for href in hrefs:\n",
    "    if not href: continue\n",
    "    if href.endswith(\"csv\") or href.endswith(\"xlsx\"):\n",
    "      if 'http' not in href: # These are strict redirects. \n",
    "        if href.startswith(\".\"): return None\n",
    "        elif url.endswith(\"/\"): full_url = url + href\n",
    "        else: full_url = f\"{url}/{href}\"\n",
    "      else: \n",
    "        full_url = href\n",
    "      print(f\"Found file: {href}\")\n",
    "      domain_link = get_domain(f\"{hospital_urls[hospital_name]['hospital_url']}\")\n",
    "      alternative_link=f\"{domain_link}/{href}\"\n",
    "      try:\n",
    "        filename = href.split(\"/\")[-1]\n",
    "        urlretrieve(alternative_link, f\"./{filename}\")\n",
    "      except:\n",
    "        pass\n",
    "      try:\n",
    "        filename = href.split(\"/\")[-1]\n",
    "        urlretrieve(href, f\"./{filename}\")\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "      crawl_and_scrape(hospital_name, alternative_link, starttime, 1) \n",
    "      crawl_and_scrape(hospital_name, full_url, starttime, 1) # terminate there.\n",
    "      \n",
    "def check_apx(hospital_name, url, starttime):\n",
    "  if 'apps.para' in url: \n",
    "      crawl_and_scrape(hospital_name=hospital_name, url=url, starttime=starttime, levels=3) #refresh levels\n",
    "\n",
    "def crawl_and_scrape(hospital_name, url, starttime, levels):\n",
    "  if levels == 0: return\n",
    "  if not is_within_time(starttime): return\n",
    "  if url in visited_urls: return\n",
    "  if is_blacklist(url): return\n",
    "\n",
    "  print(f\"Crawling & Scraping for {hospital_name}, on current URL: {url}, {levels} levels deep.\")\n",
    "  try: # malformed url sometimes\n",
    "    page = get_request(hospital_name, url)\n",
    "  except requests.exceptions.InvalidSchema: return\n",
    "  if not page: return\n",
    "  visited_urls.append(url) # Add to visited webpage list\n",
    "  soup = BeautifulSoup(page.content)\n",
    "  check_download(url, page)\n",
    "  # Check Selenium\n",
    "  check_selenium(soup, url, starttime)\n",
    "  hrefs = [a.get('href') for a in soup.findAll('a')]\n",
    "  for a_href in soup.findAll('a'):\n",
    "    if not is_within_time(starttime): break\n",
    "    href = a_href.get('href')\n",
    "    if href in visited_hrefs: continue\n",
    "    visited_hrefs.append(href)\n",
    "    if not href: continue # No href links so 'url' will be NoneType\n",
    "    if href.endswith(\".pdf\"): continue\n",
    "    full_url = url_format(url, href)\n",
    "    check_for_csv_xlsx(url, href)\n",
    "    \"\"\"\n",
    "    domain = get_domain(full_url)\n",
    "    if domain: \n",
    "      alternate_url = format_url(domain, href)\n",
    "      crawl_and_scrape(hospital_name=hospital_name, url=alternate_url, starttime=starttime, levels=levels-1)\n",
    "    \"\"\"\n",
    "    check_apx(hospital_name, full_url, starttime)\n",
    "    \n",
    "    if not full_url: continue\n",
    "  # If website is on our blacklist, skip\n",
    "    if is_blacklist(full_url): continue\n",
    "    crawl_and_scrape(hospital_name=hospital_name, url=full_url, starttime=starttime, levels=levels-1)\n",
    "    #check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\n",
    "    \n",
    "    \n",
    "    # Check to see if we can download the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "DWOPW3DgZ60X",
    "outputId": "782969e3-5326-42df-c73d-0fb1abd34517"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://www.evergreenhealth.com/patients-visitors/billing-financial/cost-estimate-ehk/app/files/public/210/EH-Chargemaster.xlsx\"'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urljoin('https://www.evergreenhealth.com/patients-visitors/billing-financial/cost-estimate-ehk/', '/app/files/public/210/EH-Chargemaster.xlsx\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uY-YbeESyIR1"
   },
   "source": [
    "# Code to Iterate Through Hospitals\n",
    "\n",
    "TODO: Redo url formatting using https://stackoverflow.com/questions/69960877/python-beautifulsoup-how-can-i-get-full-link-from-href-attribute/69960963#69960963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4P-hHWYhe-vU"
   },
   "outputs": [],
   "source": [
    "hospital_urls['Fairfax Behavioral Health Everett']['hospital_url'] = 'https://www.inova.org/patient-and-visitor-information/hospital-charges'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U1TncKnyrnY6",
    "outputId": "4bcc1aeb-5af3-4b25-82ea-90b49277d2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "Scraping the current hospital: Lake Chelan Health\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: http://www.lakechelancommunityhospital.com, 10 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/, 9 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home-clinic-home/, 8 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home-clinic-home/clinic-services/, 7 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home-clinic-home/providers/, 6 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home-clinic-home/pay-clinic-bill/, 5 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/express-care/, 4 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/for-patients-families-2/, 3 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/for-patients-families-2/physicians/, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/for-patients-families-2/patient-guide/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/bradley/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/services/surgical-center/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/speech-therapy-copy/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/pattison/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home-clinic-home/clinic-home/, 4 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/wp-content/uploads/2021/03/LCH-clinic-7-scaled.jpg, 3 levels deep.\n",
      "LCH-clinic-7-scaled.jpg is downloadable\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lyman/, 5 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home/providers/, 7 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home/clinic-services/, 7 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-clinic-clinic-home-clinic-home-clinic-home/pay-clinic-bill/, 7 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2021-12-11/, 8 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/, 7 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2021-11/, 6 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2021-10/, 5 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2021-09/, 4 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2021-08/, 3 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2021-07/, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2021-06/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2021-07-10/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2021-08-14/, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2021-08-14/?ical=1, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/child-birth-class/2021-08-21/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/child-birth-class/2021-09-18/, 3 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/child-birth-class/2021-09-18/?ical=1, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2021-10-09/, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2021-10-09/?ical=1, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/child-birth-class/2021-10-16/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2021-12/, 5 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2022-01/, 4 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2022-02/, 3 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2022-03/, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/events/2022-04/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2022-03-12/, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2022-02-12/, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2022-02-12/?ical=1, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2022-01-08/, 3 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2022-01-08/?ical=1, 2 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/child-birth-class/2021-11-20/, 5 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/child-birth-class/2021-11-20/?ical=1, 4 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/event/combined-first-aid-cpr-aed-class/2021-12-11/?ical=1, 7 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/lake-chelan-health-ems-earns-national-recognition-for-efforts-to-improve-stemi-treatment/, 8 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/author/publicrelations/, 7 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://lakechelanhealth.org/speech-language-pathologist-can-help-patients-regain-health-and-quality-of-life/, 6 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: http://www.asha.org/public, 5 levels deep.\n",
      "Selenium handling: http://www.asha.org/public\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://apps.asha.org/eweb/olsdynamicpage.aspx?webcode=olsmainpage, 4 levels deep.\n",
      "Selenium handling: https://apps.asha.org/eweb/olsdynamicpage.aspx?webcode=olsmainpage\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://apps.asha.org/eweb/OLSDynamicPage.aspx?Webcode=olsviewcart, 3 levels deep.\n",
      "Selenium handling: https://apps.asha.org/eweb/OLSDynamicPage.aspx?Webcode=olsviewcart\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/, 2 levels deep.\n",
      "Selenium handling: https://www.asha.org/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/members/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/members/\n",
      "/about/marketing/partners/parapharma-tech/\n",
      "/about/marketing/partners/parapharma-tech/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://apps.asha.org/eweb/ashalogin.aspx?site=ashacms&webcode=aulogin&endpoint=sso&returnurl=https://www.asha.org/, 1 levels deep.\n",
      "Selenium handling: https://apps.asha.org/eweb/ashalogin.aspx?site=ashacms&webcode=aulogin&endpoint=sso&returnurl=https://www.asha.org/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/aud/audiology-early-career-professional-program/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/aud/audiology-early-career-professional-program/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/advocacy/2022-asha-public-policy-agenda/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/advocacy/2022-asha-public-policy-agenda/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://solutioncenter.asha.org/?utm_source=asha&utm_medium=homepage&utm_campaign=ascb2c, 1 levels deep.\n",
      "Selenium handling: https://solutioncenter.asha.org/?utm_source=asha&utm_medium=homepage&utm_campaign=ascb2c\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"b3e14c52b720d6c73917161ee3b5da8b\", element=\"928ac05e-86ee-441c-9ad3-1681e8dd06c0\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"b3e14c52b720d6c73917161ee3b5da8b\", element=\"a5765b10-1f1d-4d36-9956-8e2e8cd01876\")> onclick element\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://careers.asha.org/getting-started/10-things-i-wish-id-known-before-becoming-a-pediatric-audiologist/, 1 levels deep.\n",
      "Selenium handling: https://careers.asha.org/getting-started/10-things-i-wish-id-known-before-becoming-a-pediatric-audiologist/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www2.asha.org/EvidenceMapLanding.aspx?id=8589943810&recentarticles=false&year=undefined&tab=allTab&filters=/8589935906/8589943810/8589943811/8589943815/,/8589935906/8589943810/8589943811/8589943815/8589943838/8589943840/, 1 levels deep.\n",
      "Selenium handling: https://www2.asha.org/EvidenceMapLanding.aspx?id=8589943810&recentarticles=false&year=undefined&tab=allTab&filters=/8589935906/8589943810/8589943811/8589943815/,/8589935906/8589943810/8589943811/8589943815/8589943838/8589943840/\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"3fe3da9bc224ea535e23cede867b4d7e\", element=\"4fed1be3-7299-4e2e-8a04-605287b07062\")> onclick element\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.un.org/en/observances/day-of-persons-with-disabilities, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/events/observances/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/events/observances/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://apps.asha.org/eweb/olsdynamicpage.aspx?title=an+alphabet+pet+parade+in+topsy-turvy+town%2C+population+26&webcode=olsdetails&utm_source=asha&utm_medium=highlight&utm_campaign=topsyturvy, 1 levels deep.\n",
      "Selenium handling: https://apps.asha.org/eweb/olsdynamicpage.aspx?title=an+alphabet+pet+parade+in+topsy-turvy+town%2C+population+26&webcode=olsdetails&utm_source=asha&utm_medium=highlight&utm_campaign=topsyturvy\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://apps.asha.org/eweb/OLSDynamicPage.aspx?webcode=olsASHALearningPass&utm_source=asha&utm_medium=highlight&utm_campaign=alp21, 1 levels deep.\n",
      "Selenium handling: https://apps.asha.org/eweb/OLSDynamicPage.aspx?webcode=olsASHALearningPass&utm_source=asha&utm_medium=highlight&utm_campaign=alp21\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://apps.asha.org/eWeb/OLSDynamicPage.aspx?Webcode=olsdetails&title=Expanding+AAC%3A+Accessible+Strategies+for+Functional+Communication&utm_source=homepage&utm_campaign=aac21&utm_id=asha, 1 levels deep.\n",
      "Selenium handling: https://apps.asha.org/eWeb/OLSDynamicPage.aspx?Webcode=olsdetails&title=Expanding+AAC%3A+Accessible+Strategies+for+Functional+Communication&utm_source=homepage&utm_campaign=aac21&utm_id=asha\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://find.asha.org/ed, 1 levels deep.\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/cefind/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/cefind/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/profind/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/profind/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/renew/?utm_source=asha&utm_medium=quicklink&utm_campaign=ODR, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/renew/?utm_source=asha&utm_medium=quicklink&utm_campaign=ODR\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/practice-portal/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/practice-portal/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: http://community.asha.org/home, 1 levels deep.\n",
      "Selenium handling: http://community.asha.org/home\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/public/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/public/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/members/international/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/members/international/\n",
      "/members/international/paraguay/\n",
      "/members/international/paraguay/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/assistants-certification-program/, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/assistants-certification-program/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://caa.asha.org/, 1 levels deep.\n",
      "Selenium handling: https://caa.asha.org/\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.ashfoundation.org/?utm_source=ASHA&utm_medium=quicklink, 1 levels deep.\n",
      "Selenium handling: https://www.ashfoundation.org/?utm_source=ASHA&utm_medium=quicklink\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.nsslha.org/?utm_source=ASHA&utm_medium=quicklink, 1 levels deep.\n",
      "Selenium handling: https://www.nsslha.org/?utm_source=ASHA&utm_medium=quicklink\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.nsslha.org/membership/join-or-renew/?utm_source=ASHA&utm_medium=quicklink, 1 levels deep.\n",
      "Selenium handling: https://www.nsslha.org/membership/join-or-renew/?utm_source=ASHA&utm_medium=quicklink\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/sig/?utm_source=ASHA&utm_medium=quicklink, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/sig/?utm_source=ASHA&utm_medium=quicklink\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: https://www.asha.org/sig/join/?utm_source=ASHA&utm_medium=quicklink, 1 levels deep.\n",
      "Selenium handling: https://www.asha.org/sig/join/?utm_source=ASHA&utm_medium=quicklink\n",
      "Crawling & Scraping for Lake Chelan Health, on current URL: /eweb/ashalogin.aspx?webcode=aulogin&ReturnURL=https%3a%2f%2fapps.asha.org%2feweb%2fOLSDynamicPage.aspx%3fWebcode%3dolsmainpage, 2 levels deep.\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8828578d89c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mvisited_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# reset visited urls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mvisited_hrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhospital_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mcheck_and_move_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# Update to show we checked this hospital already and save to json.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f3c6350499a3>\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Crawling & Scraping for {hospital_name}, on current URL: {url}, {levels} levels deep.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# malformed url sometimes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidSchema\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e0fc56d17297>\u001b[0m in \u001b[0;36mget_request\u001b[0;34m(hospital_name, url)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mInvalidURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid URL: {url}, Hospital: {hospital_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '/eweb/ashalogin.aspx?webcode=aulogin&ReturnURL=https%3a%2f%2fapps.asha.org%2feweb%2fOLSDynamicPage.aspx%3fWebcode%3dolsmainpage': No schema supplied. Perhaps you meant http:///eweb/ashalogin.aspx?webcode=aulogin&ReturnURL=https%3a%2f%2fapps.asha.org%2feweb%2fOLSDynamicPage.aspx%3fWebcode%3dolsmainpage?"
     ]
    }
   ],
   "source": [
    "for hospital_name, hospital_data in hospital_urls.items():\n",
    "  hospital_url = hospital_data['hospital_url']\n",
    "  if not hospital_url: continue # Some fields may not have a hospital url\n",
    "  if 'cdm_missing' in hospital_data.keys():\n",
    "    if hospital_data['cdm_missing']: continue\n",
    "  if hospital_data['scraped_cdm']: continue # already have the cdm\n",
    "  print(\"============================================================================\")\n",
    "  print(f\"Scraping the current hospital: {hospital_name}\")\n",
    "  subdir_path = create_subdir(hospital_name)\n",
    "  visited_urls = [] # reset visited urls\n",
    "  visited_hrefs = []\n",
    "  crawl_and_scrape(hospital_name, hospital_url, time(), 10)\n",
    "  check_and_move_files(subdir_path)\n",
    "  # Update to show we checked this hospital already and save to json.\n",
    "  hospital_data['scraped_cdm'] = True\n",
    "  #hospital_urls[hospital_name] = hospital_data\n",
    "  with open(URLS_PATH, 'w') as outfile:\n",
    "    json.dump(hospital_urls, outfile)\n",
    "  clear_output()\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nax3WhzdXNcr"
   },
   "outputs": [],
   "source": [
    "successfully_scraped = ['East Adams Rural Healthcare', 'EvergreenHealth', 'EvergreenHealth Monroe', 'Fairfax Behavioral Health Everett',\n",
    "                        'Fairfax Behavioral Health Kirkland', 'Fairfax Behavioral Health Monroe'\n",
    "                        ]\n",
    "for hospital in successfully_scraped:\n",
    "  hospital_urls[hospital]['scraped_cdm'] = True\n",
    "\n",
    "with open(URLS_PATH, 'w') as outfile:\n",
    "  json.dump(hospital_urls, outfile)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMGiEI9iDOJ7"
   },
   "outputs": [],
   "source": [
    "hospital_urls['Forks Community Hospital']['scraped_cdm'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Aq_GVH5Ddiq"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(URLS_PATH, 'w') as outfile:\n",
    "  json.dump(hospital_urls, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNherE-6t-T3"
   },
   "outputs": [],
   "source": [
    "for k, v in hospital_urls.items():\n",
    "  scraped_cdm = v['scraped_cdm']\n",
    "  if scraped_cdm:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKk8gF7cBQda"
   },
   "source": [
    "# Invalid ChargeMasters\n",
    "Some websites actually don't have the chargemaster available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyu3O47HBP-D"
   },
   "outputs": [],
   "source": [
    "missing_cdm_list = ['Columbia County Health System', 'Ferry County Health', \n",
    "                    ]\n",
    "for hospital in missing_cdm_list:\n",
    "  hospital_urls[hospital]['cdm_missing'] = True\n",
    "\n",
    "with open(URLS_PATH, 'w') as outfile:\n",
    "  json.dump(hospital_urls, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4wF1AalBbNv"
   },
   "outputs": [],
   "source": [
    "for hospital in missing_cdm_list:\n",
    "  hospital_urls[hospital]['cdm_missing'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SIJUQwXuhZA"
   },
   "outputs": [],
   "source": [
    "invalid_cdm_list = ['Cascade Valley Hospital and Clinics',  'Columbia County Health System',  'EvergreenHealth', 'EvergreenHealth Monroe', \n",
    "                    'Fairfax Behavioral Health Monroe', 'Fairfax Behavioral Health Kirkland', 'Fairfax Behavioral Health Everett', 'Garfield County Hospital District', \n",
    "                    'Harbor Regional Health', 'Inland Northwest Behavioral Health', 'Island Hospital', 'Kadlec Regional Medical Center', 'Ferry County Health', \n",
    "                    'East Adams Rural Healthcare', 'Forks Community Hospital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IuIR6mptxlt"
   },
   "outputs": [],
   "source": [
    "for invalid_cdm in invalid_cdm_list:\n",
    "  hospital_urls[invalid_cdm]['scraped_cdm'] = False\n",
    "\n",
    "with open(URLS_PATH, 'w') as outfile:\n",
    "  json.dump(hospital_urls, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Yi5EUTvCJwn"
   },
   "source": [
    "## Scrapy Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSKMXxyXEWMA"
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess, CrawlerRunner\n",
    "import re\n",
    "from crochet import setup, wait_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3v4PEiVjIR9s"
   },
   "outputs": [],
   "source": [
    "starting_urls = [v['hospital_url'] for k,v in hospital_urls.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfGJxbFqWbz4"
   },
   "outputs": [],
   "source": [
    "        \"\"\"\n",
    "        1. Check if there're any files ending in 'csv'\n",
    "        2. Send site to selenium if there're any \"onclicks\" within the HTML\n",
    "        \"\"\"\n",
    "       # print(response.url, response.request.meta.get('redirect_urls'))\n",
    "        # Check if we've downloaded any files and move to respective folder\n",
    "        \"\"\"\n",
    "\n",
    "      \n",
    "        index = -1\n",
    "        if response.url in start_urls:\n",
    "          index = start_urls.index(response.url)\n",
    "          redirect_urls = response.request.meta.get('redirect_urls')\n",
    "        elif response.url in redirect_urls:\n",
    "          redirect_index = redirect_urls.index(response_url)\n",
    "          index = start_urls.index(redirect_urls[redirect_index])\n",
    "        if index:\n",
    "          print(hospital_names[index])\n",
    "          subdirpath = create_subdir(hospital_names[index])\n",
    "          check_and_move_files(SUBDIR_PATH=subdirpath)\n",
    "        print(index)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2pj4xGNW6Eo"
   },
   "outputs": [],
   "source": [
    "visited_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7nGJuRFCLG9"
   },
   "outputs": [],
   "source": [
    "# scrape webpage\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "# text cleaning\n",
    "import re\n",
    "# Reactor restart\n",
    "from crochet import setup, wait_for\n",
    "setup()\n",
    "num_visited = 0\n",
    "\n",
    "class ScrapeCDM(scrapy.Spider):\n",
    "    \"\"\"scrape first line of  quotes from `wikiquote` by \n",
    "    Maynard James Keenan and save to json file\"\"\"\n",
    "    name = \"MJKQuotesToCsv\"\n",
    "    urls = [v['hospital_url'] for k,v in hospital_urls.items()]\n",
    "    #start_urls = ['http://www.mortongeneral.org']\n",
    "    num_visited = 0\n",
    "    hospital_names = [k for k,v in hospital_urls.items()]\n",
    "    visited_urls = []\n",
    "    index = -1\n",
    "\n",
    "    def start_requests(self):\n",
    "      for url in self.urls:\n",
    "        yield scrapy.Request(url, headers=HEADERS)\n",
    "\n",
    "    def parse(self, response):\n",
    "        \"\"\"parse data from urls\"\"\"\n",
    "        if response.url in self.visited_urls: return\n",
    "        #self.visited_urls.append(response.url)\n",
    "        #self.num_visited += 1\n",
    "        print(response.url)\n",
    "        for link in response.xpath('//a/@href').getall():\n",
    "          if 'http' not in link: link = response.url + link\n",
    "          if is_blacklist(link): continue\n",
    "        #print(self.num_visited, response_url)\n",
    "        #index = -1\n",
    "        #if response.url in start_urls:\n",
    "        #index = self.start_urls.index(response.url)\n",
    "        #redirect_urls = response.request.meta.get('redirect_urls')\n",
    "        #print(response.url)\n",
    "\n",
    "@wait_for(10)\n",
    "def run_scraper():\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(ScrapeCDM)\n",
    "    return d\n",
    "\n",
    "d = run_scraper()\n",
    "#USER_AGENT = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
    "#HEADERS = {'User-Agent': USER_AGENT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MsdZYu5GcnK"
   },
   "outputs": [],
   "source": [
    "d = run_scraper()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Chargemaster_Scraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
