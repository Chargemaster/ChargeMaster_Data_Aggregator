{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjyJBhgVt7CM"
   },
   "source": [
    "# Chargemaster Scraper\n",
    "This notebook will go over running the various code snippets which allow the web scraper to scrape chargemaster (CDM) files from WSHA associated hospitals.\n",
    "\n",
    "This was originally a Google colaboratory notebook and designed to run utilizing a Google Drive as mounted storage.\n",
    "\n",
    "This has since been modified to be able to be run locally. Some examples may not be optimized as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRDESM1YuFwU"
   },
   "source": [
    "## Install Relevant Packages\n",
    "Suggest utilizing a virtual environment. This code snippet assumes the working directory is the same as the one the notebook is located in. \n",
    "\n",
    "The \"requirements.txt\" is located one level above the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NYctZ3PHuf2m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: async-generator==1.10 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 1)) (1.10)\n",
      "Requirement already satisfied: attrs==21.2.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 2)) (21.2.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.10.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: brotlipy==0.7.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 4)) (0.7.0)\n",
      "Collecting bs4==0.0.1\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: certifi==2021.10.8 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 6)) (2021.10.8)\n",
      "Collecting cffi==1.15.0\n",
      "  Using cached cffi-1.15.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n",
      "Collecting charset-normalizer==2.0.8\n",
      "  Using cached charset_normalizer-2.0.8-py3-none-any.whl (39 kB)\n",
      "Collecting cryptography==36.0.0\n",
      "  Using cached cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "Collecting h11==0.12.0\n",
      "  Using cached h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Collecting idna==3.3\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting outcome==1.1.0\n",
      "  Using cached outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: pyOpenSSL==21.0.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 14)) (21.0.0)\n",
      "Requirement already satisfied: requests==2.26.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 15)) (2.26.0)\n",
      "Collecting selenium==4.1.0\n",
      "  Using cached selenium-4.1.0-py3-none-any.whl (958 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 17)) (1.16.0)\n",
      "Collecting sniffio==1.2.0\n",
      "  Using cached sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting sortedcontainers==2.4.0\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting soupsieve==2.3.1\n",
      "  Using cached soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Collecting trio==0.19.0\n",
      "  Using cached trio-0.19.0-py3-none-any.whl (356 kB)\n",
      "Collecting trio-websocket==0.9.2\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3==1.26.7 in /home/jihk/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 23)) (1.26.7)\n",
      "Collecting wsproto==1.0.0\n",
      "  Using cached wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting numpy==1.20.2\n",
      "  Downloading numpy-1.20.2-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.4 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==1.2.1\n",
      "  Downloading pandas-1.2.1-cp38-cp38-manylinux1_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==5.3.1\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dash==2.0.0\n",
      "  Downloading dash-2.0.0-py3-none-any.whl (7.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/jihk/anaconda3/lib/python3.8/site-packages (from pandas==1.2.1->-r ../requirements.txt (line 26)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jihk/anaconda3/lib/python3.8/site-packages (from pandas==1.2.1->-r ../requirements.txt (line 26)) (2021.3)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting Flask>=1.0.4\n",
      "  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dash-table==5.0.0\n",
      "  Downloading dash_table-5.0.0.tar.gz (3.4 kB)\n",
      "Collecting dash-html-components==2.0.0\n",
      "  Downloading dash_html_components-2.0.0.tar.gz (3.8 kB)\n",
      "Collecting flask-compress\n",
      "  Downloading Flask_Compress-1.10.1-py3-none-any.whl (7.9 kB)\n",
      "Collecting dash-core-components==2.0.0\n",
      "  Downloading dash_core_components-2.0.0.tar.gz (3.4 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from gunicorn==20.1.0->-r ../requirements.txt (line 29)) (58.0.4)\n",
      "Collecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /home/jihk/anaconda3/lib/python3.8/site-packages (from Flask>=1.0.4->dash==2.0.0->-r ../requirements.txt (line 28)) (8.0.3)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jihk/anaconda3/lib/python3.8/site-packages (from Jinja2>=3.0->Flask>=1.0.4->dash==2.0.0->-r ../requirements.txt (line 28)) (2.0.1)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[K     |████████████████████████████████| 357 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: dash-core-components, dash-html-components, dash-table\n",
      "  Building wheel for dash-core-components (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dash-core-components: filename=dash_core_components-2.0.0-py3-none-any.whl size=3821 sha256=94ca6bd0a790d4fa5157efa1de7d4998c2940f1129bd22d218701d5139f04b28\n",
      "  Stored in directory: /home/jihk/.cache/pip/wheels/52/e4/f3/16724791571a955a46d54650510c98c04ab7d339626aee27cc\n",
      "  Building wheel for dash-html-components (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dash-html-components: filename=dash_html_components-2.0.0-py3-none-any.whl size=4089 sha256=83bae66feb9a79b1962ca0fa142810f3fe4d8dc53f773fc7a7aeca15dfdc7f91\n",
      "  Stored in directory: /home/jihk/.cache/pip/wheels/73/d8/8d/92f612c03c895f19bcc56a6c54be7bb41aaa698012a5624f60\n",
      "  Building wheel for dash-table (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dash-table: filename=dash_table-5.0.0-py3-none-any.whl size=3911 sha256=e38bfbbc50662150653bc933ee12893ee26556244317963acf809948e4d4b3f6\n",
      "  Stored in directory: /home/jihk/.cache/pip/wheels/a6/fb/f5/4adf241f384634f52028f15eab6a325e77b8766a0a00816bbf\n",
      "Successfully built dash-core-components dash-html-components dash-table\n",
      "Installing collected packages: pycparser, cffi, Werkzeug, sortedcontainers, sniffio, outcome, Jinja2, itsdangerous, idna, h11, cryptography, wsproto, trio, tenacity, soupsieve, Flask, brotli, trio-websocket, plotly, numpy, flask-compress, dash-table, dash-html-components, dash-core-components, charset-normalizer, selenium, pandas, gunicorn, dash, bs4\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.6\n",
      "    Uninstalling cffi-1.14.6:\n",
      "      Successfully uninstalled cffi-1.14.6\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.2\n",
      "    Uninstalling idna-3.2:\n",
      "      Successfully uninstalled idna-3.2\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 35.0.0\n",
      "    Uninstalling cryptography-35.0.0:\n",
      "      Successfully uninstalled cryptography-35.0.0\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.2.1\n",
      "    Uninstalling soupsieve-2.2.1:\n",
      "      Successfully uninstalled soupsieve-2.2.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.4\n",
      "    Uninstalling numpy-1.21.4:\n",
      "      Successfully uninstalled numpy-1.21.4\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.4\n",
      "    Uninstalling pandas-1.3.4:\n",
      "      Successfully uninstalled pandas-1.3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\u001b[0m\n",
      "Successfully installed Flask-2.0.2 Jinja2-3.0.3 Werkzeug-2.0.2 brotli-1.0.9 bs4-0.0.1 cffi-1.15.0 charset-normalizer-2.0.8 cryptography-36.0.0 dash-2.0.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-compress-1.10.1 gunicorn-20.1.0 h11-0.12.0 idna-3.3 itsdangerous-2.0.1 numpy-1.21.2 outcome-1.1.0 pandas-1.2.1 plotly-5.3.1 pycparser-2.21 selenium-4.1.0 sniffio-1.2.0 sortedcontainers-2.4.0 soupsieve-2.3.1 tenacity-8.0.1 trio-0.19.0 trio-websocket-0.9.2 wsproto-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ../requirements.txt # Assumes this is being ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Selenium for use\n",
    "\n",
    "Requires we have a chromedriver executable. A \"setup_selenium.sh\" has been provided which downloads chromedriver executable for **linux** systems. If you're running this on another, please download the version 95 chromedriver for your corresponding operating system [here](https://chromedriver.chromium.org/downloads).\n",
    "\n",
    "One has been included as part of the repository. It is located at chargemaster/web_scraper/chromedriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jihk/Desktop/ChargeMaster_Data_Aggregator/chargemaster/web_scraper\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9747k  100 9747k    0     0  2736k      0  0:00:03  0:00:03 --:--:-- 2736k\n",
      "Archive:  chromedriver_linux64.zip\n",
      "  inflating: chromedriver            \n",
      "/home/jihk/Desktop/ChargeMaster_Data_Aggregator/examples\n"
     ]
    }
   ],
   "source": [
    "%cd ../chargemaster/web_scraper/\n",
    "!./setup_selenium.sh\n",
    "%cd ../../examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztiqJEv47qDC",
    "outputId": "a30759ee-acad-43c6-ba7e-69fbdbd348d3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, json, requests\n",
    "from time import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import InvalidURL, SSLError, ConnectionError\n",
    "from urllib3.exceptions import NewConnectionError, LocationParseError\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "from IPython.display import clear_output \n",
    "MAX_RUN_TIME=480 # 480seconds = 8 minutes max runtime per hospital\n",
    "#MAX_RUN_TIME=120\n",
    "visited_urls=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCZjseYv792r"
   },
   "source": [
    "# Loading in the JSON file from the Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b78uea8J7y8f",
    "outputId": "12dc37f8-35a9-4428-b990-3424985d9c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arbor Health': {'wsha_url': 'https://www.wsha.org/members/morton-general-hospital', 'hospital_url': 'http://www.mortongeneral.org', 'county': 'Lewis', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '20', 'scraped_cdm': True}, 'Astria Sunnyside Hospital': {'wsha_url': 'https://www.wsha.org/members/sunnyside-community-hospital-clinics', 'hospital_url': 'https://www.astria.health/locations/astria-sunnyside-hospital', 'county': 'Yakima', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '15', 'scraped_cdm': True}, 'Astria Toppenish Hospital': {'wsha_url': 'https://www.wsha.org/members/toppenish-community-hospital', 'hospital_url': 'https://www.astria.health/locations/astria-toppenish-hospital', 'county': 'Yakima', 'nbeds': 48, 'congressional_district': '4', 'legislative_district': '15', 'scraped_cdm': True}, 'Cascade Behavioral Health': {'wsha_url': 'https://www.wsha.org/members/cascade-behavioral-health', 'hospital_url': 'https://www.cascadebh.com/admissions/insurance-payment-information/rates-pricing/', 'county': 'King', 'nbeds': 137, 'congressional_district': '9', 'legislative_district': '11,33,34,47', 'scraped_cdm': True}, 'Cascade Medical': {'wsha_url': 'https://www.wsha.org/members/cascade-medical-center', 'hospital_url': 'https://cascademedical.org/patient-resources/billing', 'county': 'Chelan', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '12', 'scraped_cdm': True}, 'Cascade Valley Hospital and Clinics': {'wsha_url': 'https://www.wsha.org/members/cascade-valley-hospital-and-clinics', 'hospital_url': 'http://www.cascadevalley.org', 'county': 'Snohomish', 'nbeds': 48, 'congressional_district': '2', 'legislative_district': '10,39', 'scraped_cdm': True}, 'Columbia Basin Hospital': {'wsha_url': 'https://www.wsha.org/members/columbia-basin-hospital', 'hospital_url': 'http://www.columbiabasinhospital.org', 'county': 'Grant', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '12,13', 'scraped_cdm': True}, 'Columbia County Health System': {'wsha_url': 'https://www.wsha.org/members/columbia-county-health-system', 'hospital_url': 'http://www.cchd-wa.org', 'county': 'Columbia', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '16', 'scraped_cdm': False, 'cdm_missing': True}, 'Confluence Health': {'wsha_url': 'https://www.wsha.org/members/confluence-health', 'hospital_url': 'https://www.confluencehealth.org/patient-information/billing-insurance-information/hospital-pricing-transparency/', 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': True}, 'Confluence Health/Central Washington Hospital': {'wsha_url': 'https://www.wsha.org/members/confluence-healthcentral-washington-hospital-2', 'hospital_url': 'http://www.confluencehealth.org', 'county': 'Chelan', 'nbeds': 198, 'congressional_district': '8', 'legislative_district': '12,13', 'scraped_cdm': True}, 'Confluence Health/Wenatchee Valley Hospital &amp; Clinics': {'wsha_url': 'https://www.wsha.org/members/confluence-healthwenatchee-valley-hospital', 'hospital_url': 'http://www.confluencehealth.org', 'county': 'Chelan', 'nbeds': 20, 'congressional_district': '8', 'legislative_district': '12', 'scraped_cdm': True}, 'Coulee Medical Center': {'wsha_url': 'https://www.wsha.org/members/coulee-medical-center', 'hospital_url': 'http://www.cmccares.org', 'county': 'Grant', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '12,13', 'scraped_cdm': True}, 'East Adams Rural Healthcare': {'wsha_url': 'https://www.wsha.org/members/east-adams-rural-healthcare', 'hospital_url': 'https://www.earh.org/', 'county': 'Adams', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '9', 'scraped_cdm': True}, 'Eastern State Hospital': {'wsha_url': 'https://www.wsha.org/members/eastern-state-hospital', 'hospital_url': 'https://www.dshs.wa.gov/bhsia/division-state-hospitals/eastern-state-hospital-overview', 'county': 'Spokane', 'nbeds': 317, 'congressional_district': '5', 'legislative_district': '6', 'scraped_cdm': True}, 'EvergreenHealth': {'wsha_url': 'https://www.wsha.org/members/evergreenhealth', 'hospital_url': 'https://www.evergreenhealth.com/patients-visitors/billing-financial/cost-estimate-ehk/', 'county': 'King', 'nbeds': 318, 'congressional_district': '1', 'legislative_district': '1, 45, 48', 'scraped_cdm': True}, 'EvergreenHealth Monroe': {'wsha_url': 'https://www.wsha.org/members/evergreenhealth-monroe', 'hospital_url': 'https://www.evergreenhealth.com/ehm/patients-visitors/cost-estimate-ehm/', 'county': 'Snohomish', 'nbeds': 35, 'congressional_district': '1', 'legislative_district': '39', 'scraped_cdm': True}, 'Fairfax Behavioral Health Everett': {'wsha_url': 'https://www.wsha.org/members/fairfax-behavioral-health-everett', 'hospital_url': 'https://www.inova.org/patient-and-visitor-information/hospital-charges', 'county': 'Snohomish', 'nbeds': None, 'congressional_district': '2', 'legislative_district': '38', 'scraped_cdm': True}, 'Fairfax Behavioral Health Kirkland': {'wsha_url': 'https://www.wsha.org/members/fairfax-hospital', 'hospital_url': 'http://www.fairfaxhospital.com', 'county': 'King', 'nbeds': 221, 'congressional_district': '1', 'legislative_district': '1,45,48', 'scraped_cdm': True}, 'Fairfax Behavioral Health Monroe': {'wsha_url': 'https://www.wsha.org/members/fairfax-behavioral-health-monroe', 'hospital_url': 'https://www.fairfaxhospital.com/', 'county': 'Snohomish', 'nbeds': None, 'congressional_district': '1', 'legislative_district': '39', 'scraped_cdm': True}, 'Ferry County Health': {'wsha_url': 'https://www.wsha.org/members/ferry-county-memorial-hospital', 'hospital_url': 'http://www.fcphd.org', 'county': 'Ferry', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False, 'cdm_missing': True}, 'Forks Community Hospital': {'wsha_url': 'https://www.wsha.org/members/forks-community-hospital', 'hospital_url': 'http://www.forkshospital.org', 'county': 'Clallam', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': True}, 'Garfield County Hospital District': {'wsha_url': 'https://www.wsha.org/members/garfield-county-public-hospital-district', 'hospital_url': 'http://www.pomeroymd.com', 'county': 'Garfield', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Harbor Regional Health': {'wsha_url': 'https://www.wsha.org/members/grays-harbor-community-hospital', 'hospital_url': 'http://www.ghcares.org/', 'county': 'Grays Harbor', 'nbeds': 105, 'congressional_district': '6', 'legislative_district': '19,24', 'scraped_cdm': False}, 'Inland Northwest Behavioral Health': {'wsha_url': 'https://www.wsha.org/members/inland-northwest-behavioral-health', 'hospital_url': 'https://inlandnorthwestbh.com/', 'county': 'Spokane', 'nbeds': 100, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Island Hospital': {'wsha_url': 'https://www.wsha.org/members/island-hospital', 'hospital_url': 'http://www.islandhospital.org', 'county': 'Skagit', 'nbeds': 43, 'congressional_district': '2', 'legislative_district': '40,10', 'scraped_cdm': False}, 'Jefferson Healthcare': {'wsha_url': 'https://www.wsha.org/members/jefferson-healthcare', 'hospital_url': 'http://www.jeffersonhealthcare.org', 'county': 'Jefferson', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': True}, 'Kadlec Regional Medical Center': {'wsha_url': 'https://www.wsha.org/members/kadlec-regional-medical-center', 'hospital_url': 'http://www.kadlec.org', 'county': 'Benton', 'nbeds': 270, 'congressional_district': '4', 'legislative_district': '8,9,16', 'scraped_cdm': False}, 'Kaiser Foundation Health Plan of Washington': {'wsha_url': 'https://www.wsha.org/members/kaiser-foundation-health-plan-washington', 'hospital_url': 'http://www.kp.org/wa', 'county': 'King', 'nbeds': 15, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Kindred Hospital Seattle – First Hill': {'wsha_url': 'https://www.wsha.org/members/kindred-hospital-seattle-first-hill', 'hospital_url': 'http://www.kindredhealthcare.com', 'county': 'King', 'nbeds': 50, 'congressional_district': '7', 'legislative_district': '43', 'scraped_cdm': False}, 'Kittitas Valley Healthcare': {'wsha_url': 'https://www.wsha.org/members/kittitas-valley-healthcare', 'hospital_url': 'http://www.kvhealthcare.org', 'county': 'Kittitas', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '13', 'scraped_cdm': False}, 'Klickitat Valley Health': {'wsha_url': 'https://www.wsha.org/members/klickitat-valley-health', 'hospital_url': 'http://www.kvhealth.net', 'county': 'Klickitat', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '14', 'scraped_cdm': False}, 'Lake Chelan Health': {'wsha_url': 'https://www.wsha.org/members/lake-chelan-community-hospital', 'hospital_url': 'http://www.lakechelancommunityhospital.com', 'county': 'Chelan', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '12', 'scraped_cdm': False}, 'Legacy Health': {'wsha_url': 'https://www.wsha.org/members/legacy-health', 'hospital_url': 'http://www.legacyhealth.org', 'county': None, 'nbeds': None, 'congressional_district': '3', 'legislative_district': '17,18,49', 'scraped_cdm': False}, 'Legacy Salmon Creek Medical Center': {'wsha_url': 'https://www.wsha.org/members/legacy-salmon-creek-medical-center', 'hospital_url': 'http://www.legacyhealth.org', 'county': 'Clark', 'nbeds': 220, 'congressional_district': '3', 'legislative_district': '17,18,49', 'scraped_cdm': False}, 'Lincoln Hospital': {'wsha_url': 'https://www.wsha.org/members/lincoln-hospital', 'hospital_url': 'http://www.lincolnhospital.org', 'county': 'Lincoln', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '13', 'scraped_cdm': False}, 'Lourdes Counseling Center': {'wsha_url': 'https://www.wsha.org/members/lourdes-counseling-center', 'hospital_url': 'http://www.lourdeshealth.net', 'county': 'Benton', 'nbeds': 44, 'congressional_district': '4', 'legislative_district': '8,16', 'scraped_cdm': False}, 'Lourdes Health': {'wsha_url': 'https://www.wsha.org/members/lourdes-medical-center', 'hospital_url': 'http://www.lourdeshealth.net', 'county': 'Franklin', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '8,16', 'scraped_cdm': False}, 'Madigan Army Medical Center': {'wsha_url': 'https://www.wsha.org/members/madigan-army-medical-center', 'hospital_url': 'http://www.mamc.amedd.army.mil', 'county': 'Pierce', 'nbeds': 240, 'congressional_district': '10', 'legislative_district': '28', 'scraped_cdm': False}, 'Mason Health': {'wsha_url': 'https://www.wsha.org/members/mason-general-hospital-family-of-clinics', 'hospital_url': 'http://www.masongeneral.com', 'county': 'Mason', 'nbeds': 25, 'congressional_district': '10', 'legislative_district': '35', 'scraped_cdm': False}, 'Mid-Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/mid-valley-hospital', 'hospital_url': 'http://www.mvhealth.org', 'county': 'Okanogan', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '7,12', 'scraped_cdm': False}, 'MultiCare Allenmore Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-allenmore-hospital', 'hospital_url': 'http://www.multicare.org/allenmore', 'county': 'Pierce', 'nbeds': 70, 'congressional_district': '6', 'legislative_district': '25,26,27,28,29', 'scraped_cdm': False}, 'MultiCare Auburn Medical Center': {'wsha_url': 'https://www.wsha.org/members/multicare-auburn-medical-center', 'hospital_url': 'http://www.multicare.org/auburnmedical', 'county': 'King', 'nbeds': 195, 'congressional_district': '8', 'legislative_district': '30, 47', 'scraped_cdm': False}, 'MultiCare Capital Medical Center': {'wsha_url': 'https://www.wsha.org/members/capital-medical-center', 'hospital_url': 'http://www.capitalmedical.com', 'county': 'Thurston', 'nbeds': 107, 'congressional_district': '10', 'legislative_district': '20,22', 'scraped_cdm': False}, 'MultiCare Covington Medical Center': {'wsha_url': 'https://www.wsha.org/members/multicare-covington-medical-center', 'hospital_url': 'https://www.multicare.org/covington-medical-center/?utm_source=google&amp;utm_medium=organic&amp;utm_campaign=local', 'county': 'Pierce', 'nbeds': 58, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'MultiCare Deaconess Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-deaconess-hospital', 'hospital_url': 'https://www.multicare.org/deaconess-hospital/', 'county': 'Spokane', 'nbeds': 388, 'congressional_district': '5', 'legislative_district': '3,6', 'scraped_cdm': False}, 'MultiCare Good Samaritan  Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-good-samaritan-hospital', 'hospital_url': 'http://www.multicare.org/goodsam', 'county': 'Pierce', 'nbeds': 286, 'congressional_district': '10', 'legislative_district': '2,25,31', 'scraped_cdm': False}, 'MultiCare Health System': {'wsha_url': 'https://www.wsha.org/members/multicare-health-system', 'hospital_url': 'http://www.multicare.org', 'county': 'Pierce', 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'MultiCare Mary Bridge Children’s Hospital &amp; Health Center': {'wsha_url': 'https://www.wsha.org/members/multicare-mary-bridge-childrens-hospital-health-center', 'hospital_url': 'http://www.multicare.org/marybridge', 'county': 'Pierce', 'nbeds': 82, 'congressional_district': '6', 'legislative_district': '25,26,27,28,29', 'scraped_cdm': False}, 'MultiCare Tacoma General Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-tacoma-general-hospital', 'hospital_url': 'http://www.multicare.org/tacomageneral', 'county': 'Pierce', 'nbeds': 567, 'congressional_district': '6', 'legislative_district': '25,27,28,29', 'scraped_cdm': False}, 'MultiCare Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/multicare-valley-hospital', 'hospital_url': 'https://www.multicare.org/valley-hospital/', 'county': 'Spokane', 'nbeds': 123, 'congressional_district': '5', 'legislative_district': '4', 'scraped_cdm': False}, 'MultiMedical Systems': {'wsha_url': 'https://www.wsha.org/members/multimedical-systems', 'hospital_url': None, 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Naval Hospital': {'wsha_url': 'https://www.wsha.org/members/naval-hospital', 'hospital_url': 'https://bremerton.tricare.mil', 'county': 'Kitsap', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '35', 'scraped_cdm': False}, 'Navos': {'wsha_url': 'https://www.wsha.org/members/navos', 'hospital_url': 'http://www.navos.org', 'county': 'King', 'nbeds': 43, 'congressional_district': '7', 'legislative_district': '34', 'scraped_cdm': False}, 'Newport Hospital &amp; Health Services': {'wsha_url': 'https://www.wsha.org/members/newport-hospital-health-services', 'hospital_url': 'http://newporthospitalandhealth.org/', 'county': 'Pend Oreille', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False}, 'North Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/north-valley-hospital', 'hospital_url': 'http://www.nvhospital.org', 'county': 'Okanogan', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '7', 'scraped_cdm': False}, 'Ocean Beach Hospital &amp; Medical Clinics': {'wsha_url': 'https://www.wsha.org/members/ocean-beach-hospital', 'hospital_url': 'http://www.oceanbeachhospital.com', 'county': 'Pacific', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '19', 'scraped_cdm': False}, 'Odessa Memorial Healthcare Center': {'wsha_url': 'https://www.wsha.org/members/odessa-memorial-healthcare-center', 'hospital_url': 'http://www.omhc.org', 'county': 'Lincoln', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '13', 'scraped_cdm': False}, 'Olympic Medical Center': {'wsha_url': 'https://www.wsha.org/members/olympic-medical-center', 'hospital_url': 'http://www.olympicmedical.org', 'county': 'Clallam', 'nbeds': 126, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': False}, 'Othello Community Hospital': {'wsha_url': 'https://www.wsha.org/members/othello-community-hospital', 'hospital_url': 'http://www.othellocommunityhospital.org', 'county': 'Adams', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '9', 'scraped_cdm': False}, 'Overlake Medical Center': {'wsha_url': 'https://www.wsha.org/members/overlake-medical-center', 'hospital_url': 'http://www.overlakehospital.org', 'county': 'King', 'nbeds': 349, 'congressional_district': '9', 'legislative_district': '5,41,45,48', 'scraped_cdm': False}, 'PeaceHealth Peace Island Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-peace-island-medical-center', 'hospital_url': 'http://www.peacehealth.org/peace-island', 'county': 'San Juan', 'nbeds': 25, 'congressional_district': '2', 'legislative_district': '40', 'scraped_cdm': False}, 'PeaceHealth Southwest Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-southwest-medical-center', 'hospital_url': 'http://www.peacehealth.org/southwest', 'county': 'Clark', 'nbeds': 450, 'congressional_district': '3', 'legislative_district': '17,18,49', 'scraped_cdm': False}, 'PeaceHealth St. John Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-st-john-medical-center', 'hospital_url': 'http://www.peacehealth.org/st-john', 'county': 'Cowlitz', 'nbeds': 346, 'congressional_district': '3', 'legislative_district': '19,20', 'scraped_cdm': False}, 'PeaceHealth St. Joseph Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-st-joseph-medical-center', 'hospital_url': 'http://www.peacehealth.org/st-joseph', 'county': 'Whatcom', 'nbeds': 255, 'congressional_district': '2', 'legislative_district': '40,42', 'scraped_cdm': False}, 'PeaceHealth United General Medical Center': {'wsha_url': 'https://www.wsha.org/members/peacehealth-united-general-medical-center', 'hospital_url': 'http://www.peacehealth.org/united-general', 'county': 'Skagit', 'nbeds': 25, 'congressional_district': '2', 'legislative_district': '39', 'scraped_cdm': False}, 'Prosser Memorial Health': {'wsha_url': 'https://www.wsha.org/members/pmh-medical-center', 'hospital_url': 'http://www.prosserhealth.org', 'county': 'Benton', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '16', 'scraped_cdm': False}, 'Providence Centralia Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-centralia-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/centralia-hospital', 'county': 'Lewis', 'nbeds': 128, 'congressional_district': '3', 'legislative_district': '7,19,20', 'scraped_cdm': False}, 'Providence Holy Family Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-holy-family-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/holy-family-hospital', 'county': 'Spokane', 'nbeds': 197, 'congressional_district': '5', 'legislative_district': '3,6', 'scraped_cdm': False}, 'Providence Mount Carmel Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-mount-carmel-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/mount-carmel-hospital', 'county': 'Stevens', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False}, 'Providence Regional Medical Center Everett': {'wsha_url': 'https://www.wsha.org/members/providence-regional-medical-center-everett', 'hospital_url': 'http://washington.providence.org/hospitals/regional-medical-center', 'county': 'Snohomish', 'nbeds': 530, 'congressional_district': '2', 'legislative_district': '10,21,38,39,44', 'scraped_cdm': False}, 'Providence Sacred Heart Medical Center &amp; Children’s Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-sacred-heart-medical-center-childrens-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/sacred-heart-medical-center-and-childrens-hospital', 'county': 'Spokane', 'nbeds': 691, 'congressional_district': '5', 'legislative_district': '3,4,6,7,9', 'scraped_cdm': False}, 'Providence St. Joseph’s Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-st-josephs-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/st-josephs-hospital', 'county': 'Stevens', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '7', 'scraped_cdm': False}, 'Providence St. Mary Medical Center': {'wsha_url': 'https://www.wsha.org/members/providence-st-mary-medical-center', 'hospital_url': 'http://washington.providence.org/hospitals/st-mary', 'county': 'Walla Walla', 'nbeds': 142, 'congressional_district': '5', 'legislative_district': '8,16', 'scraped_cdm': False}, 'Providence St. Peter Hospital': {'wsha_url': 'https://www.wsha.org/members/providence-st-peter-hospital', 'hospital_url': 'http://washington.providence.org/hospitals/st-peter', 'county': 'Thurston', 'nbeds': 390, 'congressional_district': '10', 'legislative_district': '2,20,22,35', 'scraped_cdm': False}, 'Pullman Regional Hospital': {'wsha_url': 'https://www.wsha.org/members/pullman-regional-hospital', 'hospital_url': 'http://www.pullmanregional.org', 'county': 'Whitman', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Quincy Valley Medical Center': {'wsha_url': 'https://www.wsha.org/members/quincy-valley-medical-center', 'hospital_url': 'http://www.quincyhospital.org', 'county': 'Grant', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '13', 'scraped_cdm': False}, 'Rainier Springs': {'wsha_url': 'https://www.wsha.org/members/rainier-springs', 'hospital_url': 'https://rainiersprings.com/', 'county': 'Clark', 'nbeds': None, 'congressional_district': '3', 'legislative_district': '17', 'scraped_cdm': False}, 'Samaritan Healthcare': {'wsha_url': 'https://www.wsha.org/members/samaritan-healthcare', 'hospital_url': 'http://www.samaritanhealthcare.com', 'county': 'Grant', 'nbeds': 50, 'congressional_district': '4', 'legislative_district': '13', 'scraped_cdm': False}, 'Seattle Cancer Care Alliance': {'wsha_url': 'https://www.wsha.org/members/seattle-cancer-care-alliance', 'hospital_url': 'http://www.seattlecca.org', 'county': 'King', 'nbeds': 20, 'congressional_district': '7', 'legislative_district': '23, 32, 33, 34, 36, 37, 41, 43, 45, 46, 48', 'scraped_cdm': False}, 'Seattle Children’s': {'wsha_url': 'https://www.wsha.org/members/seattle-childrens', 'hospital_url': 'http://www.seattlechildrens.org', 'county': 'King', 'nbeds': 407, 'congressional_district': '7', 'legislative_district': '32, 33, 36, 41, 43, 48', 'scraped_cdm': False}, 'Shriners Hospitals for Children – Spokane': {'wsha_url': 'https://www.wsha.org/members/shriners-hospitals-for-children-spokane', 'hospital_url': 'http://www.shrinershospitalsforchildren.org/Locations/spokane', 'county': 'Spokane', 'nbeds': 69, 'congressional_district': '5', 'legislative_district': '3', 'scraped_cdm': False}, 'Skagit Regional Health': {'wsha_url': 'https://www.wsha.org/members/skagit-regional-health', 'hospital_url': 'http://www.skagitregionalhealth.org', 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Skagit Valley Hospital': {'wsha_url': 'https://www.wsha.org/members/skagit-valley-hospital', 'hospital_url': 'http://www.skagitregionalhealth.org/locations/skagit-valley-hospital', 'county': 'Skagit', 'nbeds': 173, 'congressional_district': '1', 'legislative_district': '10,40', 'scraped_cdm': False}, 'Skyline Health': {'wsha_url': 'https://www.wsha.org/members/skyline-hospital', 'hospital_url': 'http://www.myskylinehealth.org', 'county': 'Klickitat', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '14', 'scraped_cdm': False}, 'Smokey Point Behavioral Hospital': {'wsha_url': 'https://www.wsha.org/members/smokey-point-behavioral-hospital', 'hospital_url': 'http://www.smokeypointbehavioralhospital.com', 'county': 'Snohomish', 'nbeds': 115, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Snoqualmie Valley Hospital District': {'wsha_url': 'https://www.wsha.org/members/snoqualmie-valley-hospital-district', 'hospital_url': 'http://www.snoqualmiehospital.org', 'county': 'King', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '5', 'scraped_cdm': False}, 'South Sound Behavioral Hospital': {'wsha_url': 'https://www.wsha.org/members/south-sound-behavioral-hospital', 'hospital_url': 'https://www.southsoundbehavioralhospital.com/', 'county': 'Thurston', 'nbeds': None, 'congressional_district': '10', 'legislative_district': '22', 'scraped_cdm': False}, 'St. Anne Hospital': {'wsha_url': 'https://www.wsha.org/members/highline-medical-center', 'hospital_url': 'http://www.chifranciscan.org/highline-medical-center', 'county': 'King', 'nbeds': 133, 'congressional_district': '7', 'legislative_district': '11,33,34,47', 'scraped_cdm': False}, 'St. Anthony Hospital': {'wsha_url': 'https://www.wsha.org/members/st-anthony-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Anthony-Hospital/', 'county': 'Pierce', 'nbeds': 112, 'congressional_district': '6', 'legislative_district': '26', 'scraped_cdm': False}, 'St. Clare Hospital': {'wsha_url': 'https://www.wsha.org/members/st-clare-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Clare-Hospital/', 'county': 'Pierce', 'nbeds': 106, 'congressional_district': '10', 'legislative_district': '28,29', 'scraped_cdm': False}, 'St. Elizabeth Hospital': {'wsha_url': 'https://www.wsha.org/members/st-elizabeth-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Elizabeth-Hospital/', 'county': 'King', 'nbeds': 25, 'congressional_district': '8', 'legislative_district': '5,31', 'scraped_cdm': False}, 'St. Francis Hospital': {'wsha_url': 'https://www.wsha.org/members/st-francis-hospital', 'hospital_url': 'http://www.chifranciscan.org/St-Francis-Hospital/', 'county': 'King', 'nbeds': 124, 'congressional_district': '9', 'legislative_district': '30', 'scraped_cdm': False}, 'St. Joseph Medical Center': {'wsha_url': 'https://www.wsha.org/members/st-joseph-medical-center', 'hospital_url': 'http://www.chifranciscan.org/St-Joseph-Medical-Center/', 'county': 'Pierce', 'nbeds': 366, 'congressional_district': '6', 'legislative_district': '25, 27, 28, 29', 'scraped_cdm': False}, 'St. Luke’s Rehabilitation Institute': {'wsha_url': 'https://www.wsha.org/members/st-lukes-rehabilitation-institute', 'hospital_url': 'http://www.st-lukes.org', 'county': 'Spokane', 'nbeds': 102, 'congressional_district': '5', 'legislative_district': '3,4,6', 'scraped_cdm': False}, 'St. Michael Medical Center': {'wsha_url': 'https://www.wsha.org/members/harrison-medical-center', 'hospital_url': 'http://www.harrisonmedical.org', 'county': 'Kitsap', 'nbeds': 260, 'congressional_district': '6', 'legislative_district': '23,26,35', 'scraped_cdm': False}, 'Summit Pacific Medical Center': {'wsha_url': 'https://www.wsha.org/members/summit-pacific-medical-center', 'hospital_url': 'http://www.summitpacificmedicalcenter.org/', 'county': 'Grays Harbor', 'nbeds': 25, 'congressional_district': '6', 'legislative_district': '24', 'scraped_cdm': False}, 'Swedish Ballard': {'wsha_url': 'https://www.wsha.org/members/swedish-ballard', 'hospital_url': 'http://www.swedish.org/locations/ballard-campus', 'county': 'King', 'nbeds': 75, 'congressional_district': '7', 'legislative_district': '32,36,43,46', 'scraped_cdm': False}, 'Swedish Cherry Hill': {'wsha_url': 'https://www.wsha.org/members/swedish-cherry-hill', 'hospital_url': 'http://www.swedish.org/locations/cherry-hill-campus', 'county': 'King', 'nbeds': 227, 'congressional_district': '9', 'legislative_district': '11,34,36,37,41,43,46', 'scraped_cdm': False}, 'Swedish Edmonds': {'wsha_url': 'https://www.wsha.org/members/swedish-edmonds', 'hospital_url': 'http://www.swedish.org/locations/edmonds-campus', 'county': 'Snohomish', 'nbeds': 186, 'congressional_district': '7', 'legislative_district': '1,21,32', 'scraped_cdm': False}, 'Swedish First Hill': {'wsha_url': 'https://www.wsha.org/members/swedish-first-hill', 'hospital_url': 'http://www.swedish.org/locations/first-hill-campus', 'county': 'King', 'nbeds': 637, 'congressional_district': '9', 'legislative_district': '11,34,36,41,43,46', 'scraped_cdm': False}, 'Swedish Health Services': {'wsha_url': 'https://www.wsha.org/members/swedish-health-services', 'hospital_url': 'http://www.swedish.org', 'county': 'King', 'nbeds': None, 'congressional_district': '7', 'legislative_district': '1, 5, 11, 21, 32, 34, 36, 37, 41, 43, 45, 46, 48', 'scraped_cdm': False}, 'Swedish Issaquah': {'wsha_url': 'https://www.wsha.org/members/swedish-issaquah', 'hospital_url': 'http://www.swedish.org/locations/issaquah-campus', 'county': 'King', 'nbeds': 144, 'congressional_district': '8', 'legislative_district': '5,41,45,48', 'scraped_cdm': False}, 'Three Rivers Hospital': {'wsha_url': 'https://www.wsha.org/members/three-rivers-hospital', 'hospital_url': 'http://www.threerivershospital.net', 'county': 'Okanogan/Douglas', 'nbeds': 25, 'congressional_district': '4', 'legislative_district': '12', 'scraped_cdm': False}, 'Tri-State Memorial Hospital': {'wsha_url': 'https://www.wsha.org/members/tri-state-memorial-hospital', 'hospital_url': 'http://www.tristatehospital.org', 'county': 'Asotin', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Trios Health': {'wsha_url': 'https://www.wsha.org/members/trios-health', 'hospital_url': 'http://www.trioshealth.org', 'county': 'Benton', 'nbeds': 124, 'congressional_district': '4', 'legislative_district': '8,16', 'scraped_cdm': False}, 'UW Medical Center Montlake &amp; Northwest': {'wsha_url': 'https://www.wsha.org/members/uw-medicinenorthwest-hospital-medical-center', 'hospital_url': 'http://www.uwmedicine.org/northwest-hospital', 'county': 'King', 'nbeds': 281, 'congressional_district': '7', 'legislative_district': '32,36,43,46', 'scraped_cdm': False}, 'UW Medicine': {'wsha_url': 'https://www.wsha.org/members/uw-medicine', 'hospital_url': 'http://www.uwmedicine.org', 'county': 'King', 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'UW Medicine/Harborview Medical Center': {'wsha_url': 'https://www.wsha.org/members/uw-medicineharborview-medical-center', 'hospital_url': 'http://www.uwmedicine.org/harborview', 'county': 'King', 'nbeds': 413, 'congressional_district': '9', 'legislative_district': '11, 32, 34, 36, 37, 41, 43, 46', 'scraped_cdm': False}, 'UW Medicine/University of Washington Medical Center': {'wsha_url': 'https://www.wsha.org/members/uw-medicineuniversity-of-washington-medical-center', 'hospital_url': 'http://www.uwmedicine.org/uw-medical-center', 'county': 'King', 'nbeds': 473, 'congressional_district': '7', 'legislative_district': '32,34,36,37,41,43,46', 'scraped_cdm': False}, 'UW Medicine/Valley Medical Center': {'wsha_url': 'https://www.wsha.org/members/uw-medicinevalley-medical-center', 'hospital_url': 'http://www.uwmedicine.org/valley-medical-center', 'county': 'King', 'nbeds': 321, 'congressional_district': '9', 'legislative_district': '11,33,34,47', 'scraped_cdm': False}, 'VA Puget Sound Health Care System': {'wsha_url': 'https://www.wsha.org/members/va-puget-sound-health-care-system-tacoma', 'hospital_url': 'http://www.pugetsound.va.gov', 'county': 'King', 'nbeds': 459, 'congressional_district': '9', 'legislative_district': '28', 'scraped_cdm': False}, 'Virginia Mason Franciscan Health': {'wsha_url': 'https://www.wsha.org/members/chi-franciscan-health', 'hospital_url': 'https://www.innovativecareahead.org/', 'county': None, 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Virginia Mason Medical Center': {'wsha_url': 'https://www.wsha.org/members/virginia-mason-medical-center', 'hospital_url': 'http://www.virginiamason.org', 'county': 'King', 'nbeds': 371, 'congressional_district': '7', 'legislative_district': '11, 34, 36, 37, 43, 46', 'scraped_cdm': False}, 'Wellfound Behavioral Health Hospital': {'wsha_url': 'https://www.wsha.org/members/wellfound-behavioral-health-hospital', 'hospital_url': 'https://www.wellfound.org/', 'county': 'Pierce', 'nbeds': None, 'congressional_district': None, 'legislative_district': None, 'scraped_cdm': False}, 'Western State Hospital': {'wsha_url': 'https://www.wsha.org/members/western-state-hospital', 'hospital_url': 'http://www.dshs.wa.gov/bha/division-state-hospitals/western-state-hospital', 'county': 'Pierce', 'nbeds': 771, 'congressional_district': '10', 'legislative_district': '28', 'scraped_cdm': False}, 'WhidbeyHealth': {'wsha_url': 'https://www.wsha.org/members/whidbeygeneralhospital', 'hospital_url': 'https://whidbeyhealth.org/', 'county': 'Island', 'nbeds': 25, 'congressional_district': '2', 'legislative_district': '10', 'scraped_cdm': False}, 'Whitman Hospital and Medical Clinics': {'wsha_url': 'https://www.wsha.org/members/whitman-hospital-and-medical-center', 'hospital_url': 'http://www.whitmanhospital.com', 'county': 'Whitman', 'nbeds': 25, 'congressional_district': '5', 'legislative_district': '9', 'scraped_cdm': False}, 'Willapa Harbor Hospital': {'wsha_url': 'https://www.wsha.org/members/willapa-harbor-hospital', 'hospital_url': 'http://www.willapaharborhospital.com', 'county': 'Pacific', 'nbeds': 25, 'congressional_district': '3', 'legislative_district': '19', 'scraped_cdm': False}, 'Yakima Valley Memorial': {'wsha_url': 'https://www.wsha.org/members/virginia-mason-memorial-hospital', 'hospital_url': 'http://www.yakimamemorialhospital.org', 'county': 'Yakima', 'nbeds': 226, 'congressional_district': '4', 'legislative_district': '13,14,15', 'scraped_cdm': False}}\n"
     ]
    }
   ],
   "source": [
    "URLS_PATH = \"../data/hospital_urls.json\"\n",
    "hospital_urls = json.load(open(URLS_PATH))\n",
    "print(hospital_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhKTND3A8AwB"
   },
   "source": [
    "# Beginning Web Crawling\n",
    "\n",
    "Code for the web crawler/scraper itself\n",
    "\n",
    "## \"Blacklist\" websites\n",
    "Many hospitals have external links to linkedin, news articles about them, facebook, etc. and obviously we don't want the scraper to go there. So we defined a blacklist of domains that the scraper should avoid. Has been changed to be a json file in the python equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7cuB-bKjTxKl"
   },
   "outputs": [],
   "source": [
    "blacklist = ['facebook',\n",
    "             'yahoo',\n",
    "             'gmail',\n",
    "             'google', \n",
    "             'linkedin',\n",
    "             'javascript',\n",
    "             'javascript;',\n",
    "             'javascript:;',\n",
    "             'youtube',\n",
    "             'twitter',\n",
    "             'tiktok',\n",
    "             'cdc',\n",
    "             'mailto',\n",
    "             'nih.gov',\n",
    "             'coronavirus.gov',\n",
    "             'usa.gov',\n",
    "             'youtube',\n",
    "             'instagram',\n",
    "             'doh',\n",
    "             'aboutus',\n",
    "             'about-us',\n",
    "             'news',\n",
    "             'employment',\n",
    "             'mailto',\n",
    "             'covid19', \n",
    "             'covid-19',\n",
    "             'covid_19',\n",
    "             '.gov',\n",
    "             'dhs',\n",
    "             'tel:+',\n",
    "             '#content',\n",
    "             '#main',\n",
    "             'about',\n",
    "             'granthealth'\n",
    "             'forgot', \n",
    "             'password',\n",
    "             'goo.gl',\n",
    "             'tel:',\n",
    "             'apple.com',\n",
    "             'microsoft',\n",
    "             'mozilla',\n",
    "             'contactus',\n",
    "             'contactUs',\n",
    "             'ContactUs',\n",
    "             'tumblr',\n",
    "             'whatsapp',\n",
    "             'youtu',\n",
    "             'vimeo',\n",
    "             'search',\n",
    "             'wa',\n",
    "             'millcreek',\n",
    "             'gift',\n",
    "             'fchn',\n",
    "             'cellnetix',\n",
    "             'merchant',\n",
    "             'cuisine',\n",
    "             'office',\n",
    "             'flickr'\n",
    "             ]\n",
    "\"\"\"\n",
    "Adds to the list if any of the elements of \"blacklist\" are contained within url\n",
    "so if the list is non-empty, it contains a blacklist site. Returns if it contains\n",
    "a blacklist site or not. \n",
    "\"\"\"\n",
    "def is_blacklist(url):\n",
    "  blist = [site for site in blacklist if (site in url)]\n",
    "  is_blacklisted = len(blist) > 0 \n",
    "  return is_blacklisted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vKTRbYQb6mR"
   },
   "source": [
    "## Selenium\n",
    "\n",
    "Need to utilize Selenium to interact with the webpages. BeautifulSoup to crawl while using Seleniuim to interact with JS elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xR59USQncCHS"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb7KwxfrcCes"
   },
   "source": [
    "## Requests & Iterating Through Hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "W0WszNPR85qZ"
   },
   "outputs": [],
   "source": [
    "USER_AGENT = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
    "HEADERS = {'User-Agent': USER_AGENT}\n",
    "\"\"\"\n",
    "Didn't foresee that exception handling for just making the HTTP request would be\n",
    "this difficult to track down. Broke apart the web crawler into two parts, one\n",
    "for making the request and handling the HTTP status codes and one to parse\n",
    "the actual HTML returned. \n",
    "\"\"\"\n",
    "def get_request(hospital_name=None, url=None):\n",
    "  if not hospital_name or not url: return\n",
    "  req = None\n",
    "  try:\n",
    "    req = requests.get(url, headers=HEADERS)\n",
    "  except (InvalidURL, ConnectionError):\n",
    "    print(f\"Invalid URL: {url}, Hospital: {hospital_name}\")\n",
    "    try:\n",
    "      req = requests.get(url, verify=False, headers=HEADERS)\n",
    "    except: return\n",
    "  except (SSLError):\n",
    "    req = requests.get(url, verify=False, headers=HEADERS)\n",
    "    \"\"\"\n",
    "    Not doing 400s and 500s. Fiddling with headers still won't let me access some sites. \n",
    "    400s are usually invalid urls that are outdated. \n",
    "    Majority of the urls are still valid and return 200. \n",
    "    \"\"\"\n",
    "  if req.status_code >= 400: return None \n",
    "  return req\n",
    "  #print(f\"Response Code: {req.status_code}, hospital url: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbzAMArzjMAY"
   },
   "source": [
    "# Code to Check if link is downloadable\n",
    "To see if a given URL can be downloaded (E.g. in the case that it's a excel or csv file).\n",
    "Taken from https://www.codementor.io/@aviaryan/downloading-files-from-urls-in-python-77q3bs0un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bMhspbRGjPTP"
   },
   "outputs": [],
   "source": [
    "def is_downloadable(url):\n",
    "    \"\"\"\n",
    "    Does the url contain a downloadable resource\n",
    "    \"\"\"\n",
    "    try:\n",
    "      h = requests.head(url, allow_redirects=True)\n",
    "    except:\n",
    "      return False\n",
    "    header = h.headers\n",
    "    content_type = header.get('content-type')\n",
    "    if 'text' in content_type.lower():\n",
    "        return False\n",
    "    if 'html' in content_type.lower():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AOYDlt3ToG2"
   },
   "source": [
    "# Selenium Handler\n",
    "Will allow us to click for any dynamically allocated content. E.g. a download onclick\n",
    "\n",
    "Will grab all web elements with \"onclick\" by using XPATH. Iterates through these given elements and clicks them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KZFOii_WyJDS"
   },
   "outputs": [],
   "source": [
    "from urllib3.exceptions import MaxRetryError\n",
    "from selenium.common.exceptions import ElementNotInteractableException, InvalidArgumentException\n",
    "\n",
    "def selenium_handle(url, time_diff):\n",
    "  print(f\"Selenium handling: {url}\")\n",
    "  if time_diff > MAX_RUN_TIME: return\n",
    "  chrome_options = webdriver.ChromeOptions()\n",
    "  chrome_options.add_argument('--headless')\n",
    "  chrome_options.add_argument('--no-sandbox')\n",
    "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "  wd = webdriver.Chrome('../chargemaster/web_scraper/chromedriver', options=chrome_options)\n",
    "  try:\n",
    "    wd.get(url)\n",
    "  except (MaxRetryError, InvalidArgumentException): \n",
    "    wd.quit()\n",
    "    return\n",
    "\n",
    "  try:\n",
    "    elems = wd.find_elements(By.XPATH, \"//a[@onclick]\")\n",
    "    for elem in elems:\n",
    "      try:\n",
    "        print(f\"Found {str(elem)} onclick element\")\n",
    "        elem.click()\n",
    "      except ElementNotInteractableException: continue\n",
    "  except: \n",
    "    wd.quit()\n",
    "    return\n",
    "  wd.quit()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI3G9oWdzWuw"
   },
   "source": [
    "## Code to check if any hospital data has been downloaded\n",
    "Will check the working directory for any new files and move them to the subdirectory given. Moving files across file systems must be an atomic operation meaning that it is the only one run for the given process at a time. \n",
    "\n",
    "The code for this was taken from https://alexwlchan.net/2019/03/atomic-cross-filesystem-moves-in-python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ENU3nVk4zcwL"
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# https://alexwlchan.net/2019/03/atomic-cross-filesystem-moves-in-python/\n",
    "def safe_move(src, dst):\n",
    "    \"\"\"Rename a file from ``src`` to ``dst``.\n",
    "\n",
    "    *   Moves must be atomic.  ``shutil.move()`` is not atomic.\n",
    "        Note that multiple threads may try to write to the cache at once,\n",
    "        so atomicity is required to ensure the serving on one thread doesn't\n",
    "        pick up a partially saved image from another thread.\n",
    "\n",
    "    *   Moves must work across filesystems.  Often temp directories and the\n",
    "        cache directories live on different filesystems.  ``os.rename()`` can\n",
    "        throw errors if run across filesystems.\n",
    "\n",
    "    So we try ``os.rename()``, but if we detect a cross-filesystem copy, we\n",
    "    switch to ``shutil.move()`` with some wrappers to make it atomic.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.rename(src, dst)\n",
    "    except OSError as err:\n",
    "\n",
    "        if err.errno == errno.EXDEV:\n",
    "            # Generate a unique ID, and copy `<src>` to the target directory\n",
    "            # with a temporary name `<dst>.<ID>.tmp`.  Because we're copying\n",
    "            # across a filesystem boundary, this initial copy may not be\n",
    "            # atomic.  We intersperse a random UUID so if different processes\n",
    "            # are copying into `<dst>`, they don't overlap in their tmp copies.\n",
    "            copy_id = uuid.uuid4()\n",
    "            tmp_dst = \"%s.%s.tmp\" % (dst, copy_id)\n",
    "            shutil.copyfile(src, tmp_dst)\n",
    "\n",
    "            # Then do an atomic rename onto the new name, and clean up the\n",
    "            # source image.\n",
    "            os.rename(tmp_dst, dst)\n",
    "            os.unlink(src)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "IGNORE_LIST = ['.config', 'drive', '.ipynb_checkpoints'] # Google Colab or Jupyter Notebook related files. Unrelated to scraped data\n",
    "\"\"\"\n",
    "ERROR: Cross file system transfers cannot be done with os.rename, os.replace\n",
    "Try using OS methods but if it doesn't work, use shuttil.move\n",
    "Needs to be atomic\n",
    "\"\"\"\n",
    "def check_and_move_files(SUBDIR_PATH=None):\n",
    "  if not SUBDIR_PATH: return\n",
    "  filenames = os.listdir(\".\")\n",
    "  for filename in filenames:\n",
    "    if filename in IGNORE_LIST: continue\n",
    "    safe_move(f\"./{filename}\", f\"{SUBDIR_PATH}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D0ZqkJGw95z"
   },
   "source": [
    "## Code to create a subdirectory for each hospital\n",
    "\n",
    "Each hospital will have its own subdirectory created to hold all files scraped. This will help us in organizing files since the scraper will most likely pick up other files along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wGdjdtXHw8Ty"
   },
   "outputs": [],
   "source": [
    "SUBDIR_PATH = '../data/scraped_files/'\n",
    "\n",
    "\"\"\"\n",
    "Just replace all whitespace in the name with a underscore (_) for file naming conventions.\n",
    "The names are taken from the WSHA page. We can assume they do not have any\n",
    "mistakes such as having whitespace in front of the name or behind.\n",
    "\n",
    "Will return the path of the subdirectory.\n",
    "\"\"\"\n",
    "def create_subdir(hospital_name):\n",
    "  hospital_name = hospital_name.strip()\n",
    "  subdir_name = hospital_name.replace(\" \", \"_\")\n",
    "  FULL_PATH = f\"{SUBDIR_PATH}/{subdir_name}\"\n",
    "  if not os.path.isdir(FULL_PATH): \n",
    "    os.mkdir(FULL_PATH)\n",
    "  return FULL_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTUed5kDfbmK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "WIP: IT DOES NOT WORK PROPERLY YET \n",
    "\n",
    "\n",
    "High Level Plan:\n",
    "1. Find all 'a' tags\n",
    "2. From the 'a' tags, get 'href's \n",
    "3. Comb through all hrefs for resources ending in 'csv' or 'xlsx' \n",
    "4. Else, the rest of the links are recursively called into web_crawl(same_hospital_name, new_link)\n",
    "\n",
    "Cases to look out for:\n",
    "1. Staying within the domain of the hospital\n",
    "1.1 This could be being redirected to their Facebook page instead. So...\n",
    "We want to check that the new URL we're visiting is a resource within the hospital's\n",
    "webpages.\n",
    "1.2 Can check for things like matching URLs. Evergreenhealth.org/patientportal is \n",
    "valid within Evergreenhealth but... Linkedin.com/Evergreenhealth isn't. \n",
    "\n",
    "\n",
    "Going to implement an x-levels deep search. From the main website, given 'x' levels,\n",
    "It'll search x subdomains deep. E.g. If x = 10, and it goes to let's say\n",
    "hopsitalwebsite.com/patients --> x = 9 now.  From here, it'll also search\n",
    "every url and each of those will go down 8 levels. It'll be a branching effect. \n",
    "\"\"\"\n",
    "visited_urls = []\n",
    "def web_crawl(hospital_name=None, hospital_url=None, url=None, level=1, starttime=-1):\n",
    "  if level == 0: return # Reached the extent of our search.\n",
    "  #if hospital_url not in url: return # Stay within the hospital domain. See note above\n",
    "  if url in visited_urls: return # Prevent circular crawling.\n",
    "  print(f\"Name: {hospital_name}, URL being parsed: {url}, {level} levels deep.\")\n",
    "  time_diff = time() - starttime\n",
    "  if time_diff > MAX_RUN_TIME: \n",
    "    print(\"TIME RUN OUT\")\n",
    "    return\n",
    "\n",
    "  try: # malformed url sometimes\n",
    "    page = get_request(hospital_name, url)\n",
    "  except requests.exceptions.InvalidSchema:\n",
    "    return\n",
    "  if not page: return\n",
    "  visited_urls.append(url)\n",
    "  soup = BeautifulSoup(page.content)\n",
    "  soup_html = str(soup)\n",
    "  downloadble_file = True\n",
    "  content_type = str(page.headers['content-type']).lower()\n",
    "  print(content_type)\n",
    "  if 'text' in content_type or 'html' in content_type:\n",
    "    downloadable_file = False\n",
    "  #downloadable_file\n",
    "  # SELENIUM HANDLER\n",
    "  if time() - starttime < MAX_RUN_TIME:\n",
    "    if 'onclick=' in soup_html or 'onclick =' in soup_html:\n",
    "      selenium_handle(url, time_diff)\n",
    "    \n",
    "  for a_href in soup.findAll('a'):\n",
    "    if time_diff > MAX_RUN_TIME: break\n",
    "    url = a_href.get('href')\n",
    "    if not url: continue\n",
    "    full_url = url\n",
    "    if 'http' not in url and 'https' not in url: \n",
    "      full_url = hospital_url + a_href.get('href')\n",
    "    if downloadble_file:\n",
    "      filename = full_url.split(\"/\")[-1]\n",
    "      try:\n",
    "        urlretrieve(full_url, f\"./{filename}\") # download with unique \n",
    "      except: continue\n",
    "    if not is_blacklist(full_url):\n",
    "      if time() - starttime < MAX_RUN_TIME:\n",
    "        web_crawl(hospital_name=hospital_name, hospital_url=hospital_url, url=full_url, level=level-1, starttime=starttime)\n",
    "      else: return\n",
    "    else:\n",
    "      continue\n",
    "    # TODO: If it ends in xlsx or csv, download, else recursively call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFKVI84e_85"
   },
   "source": [
    "## Code for the Web Crawler + Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZIZYnzYwEmZS",
    "outputId": "f72c312e-2a4d-4d88-ab2c-716c10a6d03a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cascademedical.org'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def get_domain(url):\n",
    "  pattern = '(http[s]?:\\/\\/([w]{3}\\.)?[a-zA-Z1-9]*\\.(org|com|net)).*'\n",
    "  match = re.match(pattern, url)\n",
    "  if match: return match.group(1)\n",
    "  return match\n",
    "\n",
    "get_domain('https://cascademedical.org/patient-resources/billing') # Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ggBhRaE2kTqv"
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "APX_KEYWORD = 'apps.para'\n",
    "\n",
    "def is_within_time(starttime): return time() - starttime < MAX_RUN_TIME\n",
    "\n",
    "def is_downloadable_link(page):\n",
    "  content_type = str(page.headers['content-type']).lower()\n",
    "  if 'text' in content_type or 'html' in content_type: \n",
    "    return False\n",
    "  return True\n",
    "\n",
    "def format_url(url, href):\n",
    "  full_url = \"\"\n",
    "  if 'http' not in href: # These are strict redirects. \n",
    "    if href.startswith(\".\"): return None\n",
    "    elif url.endswith(\"/\"): full_url = url + href\n",
    "    else: full_url = f\"{url}/{href}\"\n",
    "    full_url = full_url.replace(\"//\", \"/\")\n",
    "    if 'https:/' in full_url: full_url = full_url.replace(\"https:/\", \"https://\")\n",
    "    else: full_url = full_url.replace(\"http:/\", \"http://\")\n",
    "  else: \n",
    "    full_url = href\n",
    "  return full_url\n",
    "\n",
    "def url_format(url, href):\n",
    "  full_url = \"\"\n",
    "  if 'http' not in href:\n",
    "    if 'para' in href: print(href)\n",
    "    if not full_url.endswith(\"/\"): full_url = url + \"/\" \n",
    "    full_url = urljoin(full_url, href)\n",
    "  else: full_url = href\n",
    "  return full_url\n",
    "  \n",
    "\n",
    "def get_domain(url):\n",
    "  pattern = '(http[s]?:\\/\\/([w]{3}\\.)?[a-zA-Z1-9]*\\.(org|com|net)).*'\n",
    "  if type(url) != str: return None\n",
    "  match = re.match(pattern, url)\n",
    "  if match: return match.group(1)\n",
    "  return match\n",
    "\n",
    "def check_download(full_url, page):\n",
    "  if is_downloadable_link(page):\n",
    "    filename = full_url.split(\"/\")[-1]\n",
    "    print(f\"{filename} is downloadable\")\n",
    "    try:\n",
    "      urlretrieve(full_url, f\"./{filename}\") # download with unique \n",
    "    except: pass\n",
    "\n",
    "def check_selenium(soup, url, starttime):\n",
    "  soup_html = str(soup)\n",
    "  if 'onclick' in soup_html:\n",
    "    selenium_handle(url, time() - starttime)\n",
    "\n",
    "def check_for_csv_xlsx(url, href):\n",
    "  full_url = \"\"\n",
    "  if 'http' in href: full_url = href\n",
    "  else: full_url = url_format(url, href)\n",
    "  if full_url.endswith(\"csv\") or full_url.endswith(\"xlsx\"):\n",
    "    try:\n",
    "      filename = href.split(\"/\")[-1]\n",
    "      urlretrieve(alternative_link, f\"./{filename}\")\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "def check_for_csv_xlsx_files(hospital_name, hrefs, url, starttime, levels):\n",
    "  full_url = \"\"\n",
    "  for href in hrefs:\n",
    "    if not href: continue\n",
    "    if href.endswith(\"csv\") or href.endswith(\"xlsx\"):\n",
    "      if 'http' not in href: # These are strict redirects. \n",
    "        if href.startswith(\".\"): return None\n",
    "        elif url.endswith(\"/\"): full_url = url + href\n",
    "        else: full_url = f\"{url}/{href}\"\n",
    "      else: \n",
    "        full_url = href\n",
    "      print(f\"Found file: {href}\")\n",
    "      domain_link = get_domain(f\"{hospital_urls[hospital_name]['hospital_url']}\")\n",
    "      alternative_link=f\"{domain_link}/{href}\"\n",
    "      try:\n",
    "        filename = href.split(\"/\")[-1]\n",
    "        urlretrieve(alternative_link, f\"./{filename}\")\n",
    "      except:\n",
    "        pass\n",
    "      try:\n",
    "        filename = href.split(\"/\")[-1]\n",
    "        urlretrieve(href, f\"./{filename}\")\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "      crawl_and_scrape(hospital_name, alternative_link, starttime, 1) \n",
    "      crawl_and_scrape(hospital_name, full_url, starttime, 1) # terminate there.\n",
    "      \n",
    "def check_apx(hospital_name, url, starttime):\n",
    "  if 'apps.para' in url: \n",
    "      crawl_and_scrape(hospital_name=hospital_name, url=url, starttime=starttime, levels=3) #refresh levels\n",
    "\n",
    "def crawl_and_scrape(hospital_name, url, starttime, levels):\n",
    "  if levels == 0: return\n",
    "  if not is_within_time(starttime): return\n",
    "  if url in visited_urls: return\n",
    "  if is_blacklist(url): return\n",
    "\n",
    "  print(f\"Crawling & Scraping for {hospital_name}, on current URL: {url}, {levels} levels deep.\")\n",
    "  try: # malformed url sometimes\n",
    "    page = get_request(hospital_name, url)\n",
    "  except requests.exceptions.InvalidSchema: return\n",
    "  if not page: return\n",
    "  visited_urls.append(url) # Add to visited webpage list\n",
    "  soup = BeautifulSoup(page.content)\n",
    "  check_download(url, page)\n",
    "  # Check Selenium\n",
    "  check_selenium(soup, url, starttime)\n",
    "  hrefs = [a.get('href') for a in soup.findAll('a')]\n",
    "  for a_href in soup.findAll('a'):\n",
    "    if not is_within_time(starttime): break\n",
    "    href = a_href.get('href')\n",
    "    if href in visited_hrefs: continue\n",
    "    visited_hrefs.append(href)\n",
    "    if not href: continue # No href links so 'url' will be NoneType\n",
    "    if href.endswith(\".pdf\"): continue\n",
    "    full_url = url_format(url, href)\n",
    "    check_for_csv_xlsx(url, href)\n",
    "    \"\"\"\n",
    "    domain = get_domain(full_url)\n",
    "    if domain: \n",
    "      alternate_url = format_url(domain, href)\n",
    "      crawl_and_scrape(hospital_name=hospital_name, url=alternate_url, starttime=starttime, levels=levels-1)\n",
    "    \"\"\"\n",
    "    check_apx(hospital_name, full_url, starttime)\n",
    "    \n",
    "    if not full_url: continue\n",
    "  # If website is on our blacklist, skip\n",
    "    if is_blacklist(full_url): continue\n",
    "    crawl_and_scrape(hospital_name=hospital_name, url=full_url, starttime=starttime, levels=levels-1)\n",
    "    #check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\n",
    "    \n",
    "    \n",
    "    # Check to see if we can download the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uY-YbeESyIR1"
   },
   "source": [
    "# Scrape One Hospital\n",
    "As an example, we'll go through just one hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org, 8 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org/provider-directory/, 7 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org/locations/, 6 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org/forms/contact-us/, 5 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org/, 4 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org/announcements/, 3 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org/forms/request-for-public-records/, 2 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: http://www.mortongeneral.org/patients-visitors/billing-pricing/, 1 levels deep.\n",
      "Crawling & Scraping for Arbor Health, on current URL: https://apps.para-hcfs.com/PTT/FinalLinks/ArborHealth_V2.aspx, 3 levels deep.\n",
      "Selenium handling: https://apps.para-hcfs.com/PTT/FinalLinks/ArborHealth_V2.aspx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11451/1638942186.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  wd = webdriver.Chrome('../chargemaster/web_scraper/chromedriver', options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"a78e56ba-5551-41e8-8129-51fd10f2479b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"34af23d2-f246-4aad-ba25-5efa7ecfa84b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"1b01765e-d49f-48cf-8bff-e1cb4bd1b3e6\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"c2b02c83-1a43-4ac0-86d2-ea30d6cfd52b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"fd968a76-bb55-4e77-8df4-a3e7df41a254\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"793fbc0a-17fa-4da8-8fc2-7777ebddb17b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"390c93b8-7be3-4bd7-87b4-bc42275ed489\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"8a9002ca-33aa-4c6f-8100-249a43b704d1\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"39b75212-ace4-485e-a8dc-055b2c16fbab\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"430309b8-2dc0-433c-a4a1-9865cb191521\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"be97c4f7-d369-48de-84fb-adf11601cd03\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"70e58d4c-fd62-4294-a73d-57d2d87e44a8\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"618cf4c2-7423-489e-bda0-da8e760b3134\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"d7525838-6729-402d-88df-6fc7aba9bef7\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"fa77756d-7f26-4394-a8fb-911cb7fe6f7a\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"ecaaaca2-91ec-4dc7-a424-f7f9ef16c11c\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"45f14772-6c6d-4426-be53-b35bc8d137dd\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"b720ad2c-5c42-4980-9853-5416bff67695\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"5a6188ed-93cf-4d1a-8f7c-05be8ea4bdae\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"b0bbe6b2-7302-40d9-be40-609501e9953f\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"00fd83a4-a3a3-438f-a1d8-a3835bf05668\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"da90c07d-5547-4d18-86eb-d75373edf773\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"bb3d41e3-5876-42cd-8983-39deb5cca7c9\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"9024c894-712f-48d0-955f-bf81f2a4ad9b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"5fc21548-d7f0-4598-83a4-610558292d89\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"3677f18e-d208-4da3-8502-77feafd2129c\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"5be90d44-d190-4eed-bf40-c67f68716680\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"53814405-950c-43c2-95f9-0653c34d40e2\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"d2045062-247f-4277-b4ae-ad040ec0f80b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"8c49f6e7-e6d6-4224-a7e7-86f1994d593d\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"a602b8a8-4ce2-450f-a1f4-9a84e12aa847\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"f6ba9214-1c15-449d-95b6-1bfaf29596f1\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"81125762-cea9-4eb6-ae7c-3f123dab5018\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"312d0808-f47f-4372-87d1-b7abe558262d\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"3daad3b7-958a-424c-9ca3-1cf7f8ca9a5c\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"48413139-503c-438d-ab3e-037b8041522c\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"2711499f-34a4-42cb-8ed3-09a70458815b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"ab342278-7efc-46cb-9033-052004cd8949\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"633b9215-4de6-4def-9e84-baa8d0b8439b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"e425fb41-9540-4e7d-a4a2-ccbbe6588dc1\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"721d72af-aeea-4c00-adfa-d0d11dc7a3db\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"c3f65203-243d-476e-86e1-f94a7538d9a4\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"9498269a-c0bc-4b33-b5cb-51ab60f54129\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"5fc48bd5-5c3a-4f5d-9a67-a89648e29a04\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"50fe14c7-b27c-4041-90fe-02d8e5a3d78e\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"cd345e5d-34bb-45dd-aaae-40cf003432fc\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"7c7e170a-3ae2-48cd-adb0-f542f2adfe37\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"64136521-fcd1-4056-b0e1-5f74dd6487f4\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"f089cf94-0b58-4be3-8c83-e50db26559e3\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"2df53c97-c563-4bcc-b5f4-f7a82bab9026\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"62df3f5a-5a65-44a8-81dc-146d3c7a8cf8\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"2975763d-dd4c-4c58-86d6-7b355e1fe93e\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"679fc1f7-a011-4342-8553-b7b81086f56f\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"b276e32a-ba66-4815-a743-81b0df59d0ad\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"bdec6717-7e8e-441d-a3af-4b4b7b4823cf\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"335714e1-6844-40f4-a392-f1370d1b9a1e\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"44a1d127-8933-4816-a6ae-52b7c94fc1b9\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"f3d7efcf-35da-4249-ad3e-e2163aa48701\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"41f751e4-496b-41d8-b2f7-7805bb29e717\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"f8834de4-9840-4fa9-b7e8-a9940f2def34\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"bb4eb8e6-f4c8-4d68-9f5b-1a3eb33cfd94\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"97332bb3-d4bc-448f-b902-42604f7bccee\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"4bf743d6-3aa8-4c72-9881-9ebc635e4bad\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"200dbc0e-ea8e-49d5-b4eb-4fb42bd82b22\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"f03ec111-5d4b-4741-94cf-fbbb62df5814\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"6ad7399e-f909-4df9-9c81-6b2198bd7c83\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"26dc51ec-8b5c-4bea-a21e-4bd07949173b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"e90cc66f-5998-4dfe-9ea8-f45ba4c87289\")> onclick element\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"94f327a3-3664-4690-981b-b399ab3f198c\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"890f0dfc-cc24-43f1-9c7e-d3018467d05c\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"a1debf37-30ec-46dd-a07c-29dd87da680c\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"1e921a92-a30b-44d3-b9bd-cabcc6b83a5b\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"bba8d85a-a220-486f-85ac-f22998d30fc7\")> onclick element\n",
      "Found <selenium.webdriver.remote.webelement.WebElement (session=\"db5f5b539791b7f59a101fe02738b4bb\", element=\"55868657-210e-4879-b07f-86f9912d4668\")> onclick element\n",
      "Crawling & Scraping for Arbor Health, on current URL: https://apps.para-hcfs.com/PTT/FinalLinks/ArborHealth_V2.aspx/, 3 levels deep.\n",
      "Selenium handling: https://apps.para-hcfs.com/PTT/FinalLinks/ArborHealth_V2.aspx/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11451/117308185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Initiate Scraping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# time() = current time, 8 = how many levels deep for recursive calls should it go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhospital_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Any generated files will go to this new subdirectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;31m# If website is on our blacklist, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_blacklist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#check_for_csv_xlsx_files(domain, hospital_name, href, url, starttime, levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malternate_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mcheck_apx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcheck_apx\u001b[0;34m(hospital_name, url, starttime)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_apx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'apps.para'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#refresh levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malternate_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mcheck_apx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcheck_apx\u001b[0;34m(hospital_name, url, starttime)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_apx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'apps.para'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#refresh levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrawl_and_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhospital_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcrawl_and_scrape\u001b[0;34m(hospital_name, url, starttime, levels)\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0mcheck_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;31m# Check Selenium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m   \u001b[0mcheck_selenium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m   \u001b[0mhrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0ma_href\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/2154363079.py\u001b[0m in \u001b[0;36mcheck_selenium\u001b[0;34m(soup, url, starttime)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0msoup_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'onclick'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mselenium_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_for_csv_xlsx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11451/1638942186.py\u001b[0m in \u001b[0;36mselenium_handle\u001b[0;34m(url, time_diff)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../chargemaster/web_scraper/chromedriver'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMaxRetryError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInvalidArgumentException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \"\"\"\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{self._url}{path}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     76\u001b[0m             )\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             return self.request_encode_body(\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hospital_name = 'Arbor Health'\n",
    "hospital_data = hospital_urls[hospital_name]\n",
    "hospital_url = hospital_data['hospital_url']\n",
    "# Create a subdirectory for the hospital if one doesn't already exist\n",
    "# All scraped files for this hospital will go here.\n",
    "subdir_path = create_subdir(hospital_name)\n",
    "\n",
    "# Keep track of where the Scraper has already been\n",
    "visited_urls, visited_hrefs = [], []\n",
    "\n",
    "# Initiate Scraping\n",
    "# time() = current time, 8 = how many levels deep for recursive calls should it go\n",
    "crawl_and_scrape(hospital_name, hospital_url, time(), 8)\n",
    "\n",
    "# Any generated files will go to this new subdirectory\n",
    "check_and_move_files(subdir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually ended the notebook early because it found the CDM very quickly for Arbor Health so it never got to move the files but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'91-1033860_Arbor Health Morton Hospital _standardcharges.csv.crdownload'\r\n",
      "'91-1033860_Arbor Health Morton Hospital _standardchargesDRG.csv'\r\n",
      "'91-1033860_Arbor Health Morton Hospital _standardchargesSS.csv.crdownload'\r\n",
      " Chargemaster_Scraper.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it was able to download the CDM files for Arbor into the current directory. Will manually be removing these for subsequent use."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Chargemaster_Scraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
